{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Instalando as bibliotecas que serão necessárias*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala a biblioteca \"pandas\" que será usada para manipulação de dados.\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala a biblioteca \"numpy\" que será usada para operações numéricas.\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala a biblioteca \"yfinance\" que será usada para obter dados financeiros.\n",
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instala a biblioteca \"plotly\" que será usada para a exibição de gráficos. \n",
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Importando as bibliotecas que serão necessárias*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa a biblioteca \"pandas\", que será usada para manipulação de dados.\n",
    "import pandas as pd\n",
    "# Importa a biblioteca \"numpy\", que será usada para operações numéricas.\n",
    "import numpy as np\n",
    "# Importa a biblioteca \"yfinance\" para obter alguns dados de certas ações.\n",
    "import yfinance as yf\n",
    "# Importa o módulo \"graph_objects\" da biblioteca \"plotly\" para lidar com a exibição de gráficos.\n",
    "import plotly.graph_objects as go\n",
    "# Importa o módulo datetime da biblioteca \"datetime\" para lidar com datas.\n",
    "from datetime import datetime, timedelta\n",
    "# Importa a biblioteca \"math\" para lidar com certas operações matemáticas.\n",
    "import math\n",
    "# Importa o módulo Optional da biblioteca \"typing\" para lidar com a padronização dos tipos de parâmetros opcionais das funções.\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código do backtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRIMEIRO TESTE PARA O BACKTEST\n",
    "Cálculo do S&P ta errado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valor inicial do portfólio\n",
    "valor_portfolio_inicial = 100000\n",
    "\n",
    "# Listas para armazenar o histórico do portfólio e as datas correspondentes\n",
    "historico_portfolio = []\n",
    "datas_portfolio = []\n",
    "\n",
    "# Ler todas as planilhas do arquivo Excel\n",
    "sheets = pd.read_excel('resultados_portfolio_mensal_full_modified.xlsx', sheet_name=None, header=0)\n",
    "\n",
    "for nome_sheet, df in sheets.items():\n",
    "    # Verificar se o DataFrame está vazio\n",
    "    if df.empty:\n",
    "        print(f\"A planilha '{nome_sheet}' está vazia. Pulando este período.\")\n",
    "        continue\n",
    "\n",
    "    # Verificar se as colunas esperadas estão presentes\n",
    "    colunas_esperadas = ['Acao', 'Retorno Predito', 'Retorno Real']\n",
    "    if not all(col in df.columns for col in colunas_esperadas):\n",
    "        print(f\"A planilha '{nome_sheet}' não contém as colunas esperadas. Pulando este período.\")\n",
    "        continue\n",
    "\n",
    "    # Extrair o ticker, data de início e data de fim da coluna 'Acao'\n",
    "    try:\n",
    "        # Aplicar a extração em cada linha\n",
    "        def extrair_dados(row):\n",
    "            acao_periodo = row['Acao']\n",
    "            if pd.isnull(acao_periodo):\n",
    "                return pd.Series([np.nan, np.nan, np.nan])\n",
    "            parts = acao_periodo.split(':')\n",
    "            simbolo = parts[0].strip()\n",
    "            datas = parts[1].strip().split(' - ')\n",
    "            data_inicio = pd.to_datetime(datas[0].strip(), format='%Y-%m-%d')\n",
    "            data_fim = pd.to_datetime(datas[1].strip(), format='%Y-%m-%d')\n",
    "            return pd.Series([simbolo, data_inicio, data_fim])\n",
    "\n",
    "        df[['Simbolo', 'Data_Inicio', 'Data_Fim']] = df.apply(extrair_dados, axis=1)\n",
    "        # Remover linhas com dados ausentes\n",
    "        df.dropna(subset=['Simbolo', 'Data_Inicio', 'Data_Fim'], inplace=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao extrair os dados da planilha '{nome_sheet}': {e}\")\n",
    "        continue\n",
    "\n",
    "    # Obter a data de início e fim do período a partir da primeira linha\n",
    "    data_inicio = df['Data_Inicio'].iloc[0]\n",
    "    data_fim = df['Data_Fim'].iloc[0]\n",
    "\n",
    "    # Ordenar pelo retorno predito\n",
    "    df = df.sort_values(by='Retorno Predito', ascending=False)\n",
    "\n",
    "    # Selecionar top 10%\n",
    "    n_acoes = max(int(len(df) * 0.10), 1)\n",
    "    acoes_compradas = df.head(n_acoes)\n",
    "\n",
    "    # Alocar capital igualmente entre as ações\n",
    "    valor_portfolio = valor_portfolio_inicial if not historico_portfolio else historico_portfolio[-1]\n",
    "    alocacao_por_acao = valor_portfolio / n_acoes\n",
    "\n",
    "    # Calcular o retorno real\n",
    "    retornos = acoes_compradas['Retorno Real'] / 100  # Converter porcentagem para decimal\n",
    "    valor_final = alocacao_por_acao * (1 + retornos)\n",
    "\n",
    "    # Atualizar o valor do portfólio\n",
    "    valor_portfolio = valor_final.sum()\n",
    "    historico_portfolio.append(valor_portfolio)\n",
    "    datas_portfolio.append(data_fim)\n",
    "\n",
    "    # Imprimir os resultados do período\n",
    "    print(f\"Período: {data_inicio.date()} - {data_fim.date()}\")\n",
    "    print(f\"Ações compradas: {acoes_compradas['Simbolo'].tolist()}\")\n",
    "    print(\"Retorno de cada ação:\")\n",
    "    for index, row in acoes_compradas.iterrows():\n",
    "        print(f\" - {row['Simbolo']}: {row['Retorno Real']}%\")\n",
    "    print(f\"Valor do portfólio ao final do período: ${valor_portfolio:.2f}\\n\")\n",
    "\n",
    "# Verificar se o histórico do portfólio está vazio\n",
    "if not historico_portfolio or not datas_portfolio:\n",
    "    print(\"Nenhum período foi processado com sucesso. Verifique os dados e tente novamente.\")\n",
    "else:\n",
    "    # Criar DataFrame com o histórico do portfólio\n",
    "    df_portfolio = pd.DataFrame({\n",
    "        'Data': datas_portfolio,\n",
    "        'Valor': historico_portfolio\n",
    "    })\n",
    "    # Ordenar por data\n",
    "    df_portfolio.sort_values(by='Data', inplace=True)\n",
    "    df_portfolio.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # 5. Obter dados do S&P500\n",
    "    data_inicio_total = df_portfolio['Data'].iloc[0] - timedelta(days=5)\n",
    "    data_fim_total = df_portfolio['Data'].iloc[-1] + timedelta(days=5)\n",
    "    sp500 = yf.download('^GSPC', start=data_inicio_total, end=data_fim_total)\n",
    "    print(\"Colunas disponíveis em sp500:\", sp500.columns)\n",
    "\n",
    "    # Determinar a coluna de preço a ser usada\n",
    "    if 'Adj Close' in sp500.columns:\n",
    "        price_column = 'Adj Close'\n",
    "    elif 'Close' in sp500.columns:\n",
    "        price_column = 'Close'\n",
    "    else:\n",
    "        raise KeyError(\"Nenhuma coluna de preço ('Adj Close' ou 'Close') encontrada em sp500\")\n",
    "\n",
    "    # Resetar o índice para ter a coluna 'Date'\n",
    "    sp500.reset_index(inplace=True)\n",
    "\n",
    "    # Remover informações de fuso horário da coluna 'Date'\n",
    "    sp500['Date'] = sp500['Date'].dt.tz_localize(None)\n",
    "\n",
    "    # Verificar os tipos de dados das colunas de datas\n",
    "    print(\"dtype de sp500['Date']:\", sp500['Date'].dtype)\n",
    "    print(\"dtype de df_portfolio['Data']:\", df_portfolio['Data'].dtype)\n",
    "\n",
    "    # Calcular retorno acumulado do S&P500\n",
    "    sp500['Retorno'] = sp500[price_column].pct_change().fillna(0)\n",
    "    sp500['Retorno Acumulado'] = (1 + sp500['Retorno']).cumprod()\n",
    "\n",
    "    # Interpolar o retorno acumulado do S&P500 nas datas do portfólio\n",
    "    sp500_interp = sp500[['Date', 'Retorno Acumulado']].set_index('Date').reindex(\n",
    "        df_portfolio['Data'], method='ffill')\n",
    "\n",
    "    # Após reindexar, resetamos o índice\n",
    "    sp500_interp.reset_index(inplace=True)\n",
    "\n",
    "    # Verificar as colunas e as primeiras linhas\n",
    "    print(\"Colunas de sp500_interp após reset_index:\", sp500_interp.columns)\n",
    "    print(\"Primeiras linhas de sp500_interp:\")\n",
    "    print(sp500_interp.head())\n",
    "\n",
    "    # Ajustar o acesso à coluna de datas de sp500_interp\n",
    "    if 'Date' in sp500_interp.columns:\n",
    "        date_column = 'Date'\n",
    "    elif 'index' in sp500_interp.columns:\n",
    "        date_column = 'index'\n",
    "    elif 'Data' in sp500_interp.columns:\n",
    "        date_column = 'Data'\n",
    "    else:\n",
    "        print(\"A coluna de datas não foi encontrada em sp500_interp.\")\n",
    "        print(\"Colunas disponíveis:\", sp500_interp.columns)\n",
    "        raise KeyError(\"Coluna de datas não encontrada em sp500_interp\")\n",
    "\n",
    "    # Calcular retorno acumulado da estratégia\n",
    "    df_portfolio['Retorno'] = df_portfolio['Valor'].pct_change().fillna(0)\n",
    "    df_portfolio['Retorno Acumulado'] = (1 + df_portfolio['Retorno']).cumprod()\n",
    "\n",
    "    # 6. Plotar o gráfico comparativo usando Plotly\n",
    "    trace_estrategia = go.Scatter(\n",
    "        x=df_portfolio['Data'],\n",
    "        y=df_portfolio['Retorno Acumulado'],\n",
    "        mode='lines+markers',\n",
    "        name='Retorno Acumulado da Estratégia',\n",
    "        yaxis='y1'\n",
    "    )\n",
    "\n",
    "    trace_sp500 = go.Scatter(\n",
    "        x=sp500_interp[date_column],\n",
    "        y=sp500_interp['Retorno Acumulado'],\n",
    "        mode='lines+markers',\n",
    "        name='Retorno Acumulado do S&P500',\n",
    "        yaxis='y1'\n",
    "    )\n",
    "\n",
    "    trace_capital = go.Scatter(\n",
    "        x=df_portfolio['Data'],\n",
    "        y=df_portfolio['Valor'],\n",
    "        mode='lines+markers',\n",
    "        name='Capital do Portfólio',\n",
    "        yaxis='y2'\n",
    "    )\n",
    "\n",
    "    data = [trace_estrategia, trace_sp500, trace_capital]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title='Comparação de Retorno Acumulado e Capital do Portfólio',\n",
    "        xaxis=dict(title='Data'),\n",
    "        yaxis=dict(\n",
    "            title='Retorno Acumulado',\n",
    "            side='left',\n",
    "            showgrid=False,\n",
    "            zeroline=False\n",
    "        ),\n",
    "        yaxis2=dict(\n",
    "            title='Capital do Portfólio',\n",
    "            overlaying='y',\n",
    "            side='right',\n",
    "            showgrid=False,\n",
    "            zeroline=False\n",
    "        ),\n",
    "        legend=dict(x=0.01, y=0.99)\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    fig.show()\n",
    "\n",
    "# 7. Plotar o histograma da distribuição dos retornos da estratégia\n",
    "\n",
    "# Remover possíveis NaNs ou valores infinitos\n",
    "retornos = df_portfolio['Retorno'].dropna().replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# Criar o histograma dos retornos\n",
    "histograma = go.Figure(data=[go.Histogram(\n",
    "    x=retornos * 100,  # Converter para porcentagem\n",
    "    xbins=dict(\n",
    "        start=retornos.min() * 100,\n",
    "        end=retornos.max() * 100,\n",
    "        size=1  # Intervalo de 1% entre as barras\n",
    "    ),\n",
    "    marker_color='blue',\n",
    "    opacity=0.75\n",
    ")])\n",
    "\n",
    "histograma.update_layout(\n",
    "    title='Distribuição dos Retornos da Estratégia',\n",
    "    xaxis_title='Retorno (%)',\n",
    "    yaxis_title='Frequência',\n",
    "    bargap=0.2,\n",
    "    bargroupgap=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTE 2 pq o primeiro tava dando problema com o S&P500\n",
    "\n",
    "Tudo fragmentado pra facilitar identificação de erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from datetime import timedelta\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# Valor inicial do portfólio\n",
    "valor_portfolio_inicial = 100000\n",
    "\n",
    "# Listas para armazenar o histórico do portfólio e as datas correspondentes\n",
    "historico_portfolio = []\n",
    "datas_portfolio = []\n",
    "datas_inicio_portfolio = []\n",
    "retornos_estrategia_periodo = []\n",
    "retornos_sp500_periodo = []\n",
    "\n",
    "# Nome do arquivo Excel\n",
    "arquivo_excel = 'resultados_portfolio_mensal_full_modified.xlsx'\n",
    "\n",
    "# Tentar ler o arquivo Excel\n",
    "try:\n",
    "    sheets = pd.read_excel(arquivo_excel, sheet_name=None, header=0)\n",
    "    print(f\"Arquivo '{arquivo_excel}' lido com sucesso.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Arquivo '{arquivo_excel}' não encontrado. Verifique o caminho e o nome do arquivo.\")\n",
    "    exit()\n",
    "\n",
    "# Função para extrair dados de cada linha\n",
    "def extrair_dados(row):\n",
    "    acao_periodo = row['Acao']\n",
    "    if pd.isnull(acao_periodo):\n",
    "        return pd.Series([np.nan, np.nan, np.nan])\n",
    "    parts = acao_periodo.split(':')\n",
    "    if len(parts) != 2:\n",
    "        return pd.Series([np.nan, np.nan, np.nan])\n",
    "    simbolo = parts[0].strip()\n",
    "    datas = parts[1].strip().split(' - ')\n",
    "    if len(datas) != 2:\n",
    "        return pd.Series([np.nan, np.nan, np.nan])\n",
    "    try:\n",
    "        data_inicio = pd.to_datetime(datas[0].strip(), dayfirst=True).normalize()\n",
    "        data_fim = pd.to_datetime(datas[1].strip(), dayfirst=True).normalize()\n",
    "    except ValueError:\n",
    "        return pd.Series([np.nan, np.nan, np.nan])\n",
    "    return pd.Series([simbolo, data_inicio, data_fim])\n",
    "\n",
    "# Processar cada planilha\n",
    "for nome_sheet, df in sheets.items():\n",
    "    print(f\"\\nProcessando a planilha: {nome_sheet}\")\n",
    "    \n",
    "    # Verificar se o DataFrame está vazio\n",
    "    if df.empty:\n",
    "        print(f\"A planilha '{nome_sheet}' está vazia. Pulando este período.\")\n",
    "        continue\n",
    "\n",
    "    # Verificar se as colunas esperadas estão presentes\n",
    "    colunas_esperadas = ['Acao', 'Retorno Predito', 'Retorno Real']\n",
    "    if not all(col in df.columns for col in colunas_esperadas):\n",
    "        print(f\"A planilha '{nome_sheet}' não contém as colunas esperadas: {colunas_esperadas}. Pulando este período.\")\n",
    "        continue\n",
    "\n",
    "    # Aplicar a extração em cada linha\n",
    "    df[['Simbolo', 'Data_Inicio', 'Data_Fim']] = df.apply(extrair_dados, axis=1)\n",
    "\n",
    "    # Remover linhas com dados ausentes\n",
    "    linhas_antes = len(df)\n",
    "    df.dropna(subset=['Simbolo', 'Data_Inicio', 'Data_Fim'], inplace=True)\n",
    "    linhas_depois = len(df)\n",
    "    print(f\"Linhas processadas: {linhas_depois} (removidas {linhas_antes - linhas_depois} linhas com dados ausentes)\")\n",
    "\n",
    "    # Verificar se após a extração o DataFrame está vazio\n",
    "    if df.empty:\n",
    "        print(f\"A planilha '{nome_sheet}' não possui dados válidos após a extração. Pulando este período.\")\n",
    "        continue\n",
    "\n",
    "    # Obter a data de início e fim do período a partir da primeira linha\n",
    "    data_inicio = df['Data_Inicio'].iloc[0]\n",
    "    data_fim = df['Data_Fim'].iloc[0]\n",
    "\n",
    "    print(f\"Período: {data_inicio.date()} - {data_fim.date()}\")\n",
    "\n",
    "    # Ordenar pelo retorno predito\n",
    "    df = df.sort_values(by='Retorno Predito', ascending=False)\n",
    "\n",
    "    # Selecionar top 10%\n",
    "    n_acoes = max(int(len(df) * 0.10), 1)\n",
    "    acoes_compradas = df.head(n_acoes)\n",
    "    print(f\"Selecionadas {n_acoes} ações para o portfólio.\")\n",
    "\n",
    "    # Alocar capital igualmente entre as ações\n",
    "    if not historico_portfolio:\n",
    "        valor_portfolio_anterior = valor_portfolio_inicial\n",
    "    else:\n",
    "        valor_portfolio_anterior = historico_portfolio[-1]\n",
    "    valor_portfolio = valor_portfolio_anterior\n",
    "    alocacao_por_acao = valor_portfolio / n_acoes\n",
    "\n",
    "    # Calcular o retorno real\n",
    "    retornos = acoes_compradas['Retorno Real'] / 100  # Converter porcentagem para decimal\n",
    "    valor_final = alocacao_por_acao * (1 + retornos)\n",
    "\n",
    "    # Atualizar o valor do portfólio\n",
    "    valor_portfolio = valor_final.sum()\n",
    "    historico_portfolio.append(valor_portfolio)\n",
    "    datas_portfolio.append(data_fim)\n",
    "    datas_inicio_portfolio.append(data_inicio)\n",
    "\n",
    "    # Calcular o retorno do período\n",
    "    retorno_periodo = (valor_portfolio - valor_portfolio_anterior) / valor_portfolio_anterior * 100  # Em porcentagem\n",
    "    retornos_estrategia_periodo.append(retorno_periodo)\n",
    "\n",
    "    # Imprimir os resultados do período\n",
    "    print(f\"Ações compradas: {acoes_compradas['Simbolo'].tolist()}\")\n",
    "    print(\"Retorno de cada ação:\")\n",
    "    for index, row in acoes_compradas.iterrows():\n",
    "        print(f\" - {row['Simbolo']}: {row['Retorno Real']}%\")\n",
    "    print(f\"Retorno do período: {retorno_periodo:.2f}%\")\n",
    "    print(f\"Valor do portfólio ao final do período: ${valor_portfolio:.2f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se o histórico do portfólio está vazio\n",
    "if not historico_portfolio or not datas_portfolio:\n",
    "    print(\"Nenhum período foi processado com sucesso. Verifique os dados e tente novamente.\")\n",
    "    exit()\n",
    "else:\n",
    "    # Criar DataFrame com o histórico do portfólio\n",
    "    df_portfolio = pd.DataFrame({\n",
    "        'Data': datas_portfolio,\n",
    "        'Valor': historico_portfolio\n",
    "    })\n",
    "    # Ordenar por data\n",
    "    df_portfolio.sort_values(by='Data', inplace=True)\n",
    "    df_portfolio.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(\"\\nHistórico do Portfólio:\")\n",
    "    print(df_portfolio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter dados do S&P500\n",
    "data_inicio_total = min(datas_inicio_portfolio) - timedelta(days=5)\n",
    "data_fim_total = max(datas_portfolio) + timedelta(days=5)\n",
    "print(f\"\\nBaixando dados do S&P500 de {data_inicio_total.date()} a {data_fim_total.date()}.\")\n",
    "    \n",
    "try:\n",
    "    # Baixar dados do S&P500 sem o parâmetro 'group_by'\n",
    "    sp500 = yf.download('^GSPC', start=data_inicio_total, end=data_fim_total)\n",
    "    print(\"Dados do S&P500 baixados com sucesso.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao baixar dados do S&P500: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Resetar o índice para transformar o índice em coluna\n",
    "sp500.reset_index(inplace=True)\n",
    "\n",
    "# Verificar se as colunas são MultiIndex\n",
    "if isinstance(sp500.columns, pd.MultiIndex):\n",
    "    # Achatar as colunas combinando os níveis\n",
    "    sp500.columns = [' '.join(col).strip() for col in sp500.columns.values]\n",
    "    print(\"Ajustando colunas de MultiIndex para nível único.\")\n",
    "else:\n",
    "    print(\"Colunas de sp500 são de nível único.\")\n",
    "\n",
    "# Converter os nomes das colunas para minúsculas para facilitar a comparação\n",
    "sp500.columns = [col.lower() for col in sp500.columns]\n",
    "print(f\"Colunas em sp500 após conversão para minúsculas: {sp500.columns.tolist()}\")\n",
    "\n",
    "# Verificar o nome da coluna de data\n",
    "date_column_name = None\n",
    "for col in sp500.columns:\n",
    "    if 'date' in col:\n",
    "        date_column_name = col\n",
    "        break\n",
    "\n",
    "if date_column_name is None:\n",
    "    print(\"Nenhuma coluna de data encontrada em sp500.\")\n",
    "    exit()\n",
    "\n",
    "if date_column_name != 'date':\n",
    "    sp500.rename(columns={date_column_name: 'date'}, inplace=True)\n",
    "    print(f\"Renomeada a coluna de data para 'date'.\")\n",
    "\n",
    "# Remover informações de fuso horário e normalizar a data\n",
    "sp500['date'] = pd.to_datetime(sp500['date']).dt.tz_localize(None).dt.normalize()\n",
    "\n",
    "# Determinar a coluna de preço a ser usada\n",
    "price_column = None\n",
    "for col in sp500.columns:\n",
    "    if 'adj close' in col.lower():\n",
    "        price_column = col\n",
    "        break\n",
    "if price_column is None:\n",
    "    for col in sp500.columns:\n",
    "        if 'close' in col.lower():\n",
    "            price_column = col\n",
    "            break\n",
    "\n",
    "if price_column is None:\n",
    "    raise KeyError(f\"Nenhuma coluna de preço ('Adj Close' ou 'Close') encontrada em sp500. Colunas disponíveis: {sp500.columns.tolist()}\")\n",
    "\n",
    "print(f\"Coluna de preço selecionada: '{price_column}'\")\n",
    "\n",
    "# Criar sp500_prices com 'date' como coluna\n",
    "sp500_prices = sp500[['date', price_column]].rename(columns={price_column: 'Price'})\n",
    "\n",
    "print(f\"Colunas em sp500_prices: {sp500_prices.columns.tolist()}\")\n",
    "\n",
    "# Calcular Retorno do S&P500 (não acumulado)\n",
    "sp500_prices['Retorno'] = sp500_prices['Price'].pct_change().fillna(0)\n",
    "\n",
    "# Verificar se 'Retorno' foi criado\n",
    "if 'Retorno' not in sp500_prices.columns:\n",
    "    print(\"Erro: A coluna 'Retorno' não foi criada em sp500_prices.\")\n",
    "    print(f\"Colunas disponíveis em sp500_prices: {sp500_prices.columns.tolist()}\")\n",
    "    exit()\n",
    "else:\n",
    "    print(\"'Retorno' criado com sucesso em sp500_prices.\")\n",
    "    print(sp500_prices[['date', 'Price', 'Retorno']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar required_dates\n",
    "required_dates = pd.Series(datas_inicio_portfolio + datas_portfolio).drop_duplicates()\n",
    "required_dates = pd.to_datetime(required_dates).dt.normalize()\n",
    "required_dates = required_dates.to_frame(name='date')\n",
    "required_dates.sort_values('date', inplace=True)\n",
    "required_dates.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Garantir que não há duplicatas em required_dates\n",
    "required_dates.drop_duplicates(subset='date', inplace=True)\n",
    "\n",
    "# Realizar o merge_asof para alinhar os preços do S&P500 com as datas do portfólio\n",
    "prices_at_required_dates = pd.merge_asof(\n",
    "    required_dates.sort_values('date'),\n",
    "    sp500_prices.sort_values('date'),\n",
    "    on='date',\n",
    "    direction='backward'\n",
    ")\n",
    "\n",
    "# Verificar se há NaNs após o merge\n",
    "na_prices = prices_at_required_dates['Price'].isna().sum()\n",
    "if na_prices > 0:\n",
    "    print(f\"Atenção: {na_prices} datas no portfólio não têm correspondência no S&P500.\")\n",
    "\n",
    "# Criar um dicionário mapeando datas a preços\n",
    "date_price_dict = dict(zip(prices_at_required_dates['date'], prices_at_required_dates['Price']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular os retornos do S&P500 para cada período\n",
    "for i in range(len(datas_inicio_portfolio)):\n",
    "    data_inicio = datas_inicio_portfolio[i].normalize()\n",
    "    data_fim = datas_portfolio[i].normalize()\n",
    "\n",
    "    price_inicio = date_price_dict.get(data_inicio)\n",
    "    price_fim = date_price_dict.get(data_fim)\n",
    "\n",
    "    if pd.isna(price_inicio) or pd.isna(price_fim):\n",
    "        print(f\"Não foi possível obter preços para o período {data_inicio.date()} - {data_fim.date()}\")\n",
    "        retorno_sp500_periodo = np.nan\n",
    "    else:\n",
    "        retorno_sp500_periodo = (price_fim - price_inicio) / price_inicio * 100\n",
    "        print(f\"Retorno do S&P500 no período {data_inicio.date()} - {data_fim.date()}: {retorno_sp500_periodo:.2f}%\")\n",
    "    retornos_sp500_periodo.append(retorno_sp500_periodo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar DataFrame com os retornos por período\n",
    "df_returns = pd.DataFrame({\n",
    "    'Data_Inicio': datas_inicio_portfolio,\n",
    "    'Data_Fim': datas_portfolio,\n",
    "    'Retorno_Estrategia': retornos_estrategia_periodo,\n",
    "    'Retorno_SP500': retornos_sp500_periodo\n",
    "})\n",
    "\n",
    "# Remover períodos onde o retorno do S&P500 é NaN\n",
    "df_returns.dropna(subset=['Retorno_SP500'], inplace=True)\n",
    "\n",
    "# Formatar as datas para serem usadas como rótulos no gráfico\n",
    "df_returns['Período'] = df_returns['Data_Fim'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "print(\"\\nDataFrame com Retornos por Período:\")\n",
    "print(df_returns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotar o gráfico de barras duplo dos retornos por período\n",
    "fig_bar = go.Figure(data=[\n",
    "    go.Bar(name='Estratégia', x=df_returns['Período'], y=df_returns['Retorno_Estrategia']),\n",
    "    go.Bar(name='S&P500', x=df_returns['Período'], y=df_returns['Retorno_SP500'])\n",
    "])\n",
    "\n",
    "fig_bar.update_layout(\n",
    "    barmode='group',\n",
    "    title='Retornos por Período: Estratégia vs S&P500',\n",
    "    xaxis_title='Período',\n",
    "    yaxis_title='Retorno (%)',\n",
    "    legend=dict(x=0.01, y=0.99)\n",
    ")\n",
    "\n",
    "fig_bar.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AJEITAR O GRÁFICO QUE FICOU RUIM(provavelmente por conta da escala)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráfico de barras verticais sobrepostas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Dados de exemplo\n",
    "x_values = [\"Categoria A\", \"Categoria B\", \"Categoria C\"]\n",
    "y_values_1 = [10, 20, 15]\n",
    "y_values_2 = [5, 15, 10]\n",
    "\n",
    "# Criação das barras empilhadas\n",
    "fig = go.Figure()\n",
    "\n",
    "# Primeira barra (base)\n",
    "fig.add_trace(go.Bar(\n",
    "    x=x_values,\n",
    "    y=y_values_1,\n",
    "    name='Série 1'\n",
    "))\n",
    "\n",
    "# Segunda barra (sobreposta na anterior)\n",
    "fig.add_trace(go.Bar(\n",
    "    x=x_values,\n",
    "    y=y_values_2,\n",
    "    name='Série 2'\n",
    "))\n",
    "\n",
    "# Configuração do layout para barras empilhadas\n",
    "fig.update_layout(\n",
    "    barmode='stack',\n",
    "    title='Gráfico de Barras Verticalmente Sobrepostas',\n",
    "    xaxis_title='Categorias',\n",
    "    yaxis_title='Valores'\n",
    ")\n",
    "\n",
    "# Exibe o gráfico\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_serie_line_graph(serie: pd.Series, serie_title: Optional[str] = \"\", serie_xaxis_title: Optional[str] = \"\", \n",
    "                               serie_yaxis_title: Optional[str] = \"\") -> None:\n",
    "    '''\n",
    "        Description:\n",
    "            Essa função é responsável por realizar o plot de uma série temporal.\n",
    "        Args:\n",
    "            serie (pd.Series): Série temporal cujos dados serão utilizados para o plot. Os valores de tal série temporal estarão no eixo y,\n",
    "            enquanto os índices dessa série estarão no eixo x.\n",
    "            title (string):\n",
    "            xaxis_title (string):\n",
    "            yaxis_title (string):\n",
    "            \n",
    "        Return:\n",
    "            Essa função plota a série temporal, mas não retorna nada.\n",
    "    '''\n",
    "    \n",
    "    # Cria a figure onde a série temporal em questão será plotada.\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Adiciona o gráfico da série temporal em questão ao plot.\n",
    "    fig.add_trace(go.Scatter(\n",
    "        # Define os valores do eixo x do plot.\n",
    "        x = serie.index,\n",
    "        # Define os valores do eixo y do plot.\n",
    "        y = serie.values,\n",
    "        # Define o tipo do gráfico que será plotado.\n",
    "        mode = \"lines\"\n",
    "    ))\n",
    "    \n",
    "    # Adiciona algumas legendas ao plot.\n",
    "    fig.update_layout(\n",
    "        # Adiciona um título ao plot.\n",
    "        title = serie_title,\n",
    "        # Adiciona uma legenda ao eixo x do plot.\n",
    "        xaxis_title = serie_xaxis_title,\n",
    "        # Adiciona uma legenda ao eixo y do plot.\n",
    "        yaxis_title = serie_yaxis_title\n",
    "    )\n",
    "    \n",
    "    # Exibe o plot criado.\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Cria um título para o plot.\n",
    "title = f\"Retornos logarítmicos diários de {ticker1}\"\n",
    "# Cria uma legenda para o eixo x do plot.\n",
    "xaxis_title = \"Data\"\n",
    "# Cria uma legenda para o eixo y do plot.\n",
    "yaxis_title = \"Valor\"\n",
    "\n",
    "# Cria o plot da série temporal dos log retornos diários do \"ticker1\".\n",
    "plot_time_serie_line_graph(ticker1_daily_logarithmic_return, title, xaxis_title, yaxis_title)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiples_time_series_line_graphs(data_list: list, serie_title: Optional[str] = \"\", serie_xaxis_title: Optional[str] = \"\", \n",
    "                               serie_yaxis_title: Optional[str] = \"\") -> None:\n",
    "    '''\n",
    "        Description:\n",
    "            Esta função exibe em um mesmo plot múltiplos gráficos de séries temporais. \n",
    "        Args:\n",
    "            data_list (list): Lista contendo as séries temporais cujos gráficos serão exibidos no plot. Os valores de tais séries temporais\n",
    "                              estarão no eixo y, enquanto os índices dessas séries estarão no eixo x.\n",
    "            title (string) [Optional]: Título do plot.\n",
    "            xaxis_title (string) [Optional]: Título do eixo x do plot.\n",
    "            yaxis_title (string) [Optional]: Título do eixo y do plot.\n",
    "        Return:\n",
    "            None: A função exibe os gráficos, mas não retorna nenhum valor.  \n",
    "        Errors:\n",
    "            TypeError: É esperado que todas os elementos da lista \"data_list\" sejam objetos do tipo pd.Series, isto é, que sejam séries temporais.\n",
    "            ValueError: É esperado que todas as séries temporais presentes na variável \"data_list\" possuam os mesmos índices. \n",
    "            TypeError: É esperado que todas as séries temporais presentes na variável data_list possuam um atributo \"name\".\n",
    "    '''    \n",
    "\n",
    "    # Verifica se todos os elementos presentes na lista \"data_list\" são séries temporais.\n",
    "    are_all_data_time_series = all(isinstance(df, pd.Series) for df in data_list)\n",
    "    \n",
    "    # Retorna um erro caso algum dos dados presentes na variável \"data_list\" não seja uma série temporal\n",
    "    if not are_all_data_time_series:\n",
    "        raise TypeError(\"Todos os dados presentes no parâmetro 'data_list' devem ser séries temporais.\")\n",
    "    \n",
    "    # Verifica se as séries temporais presentes na variável \"data_list\" possuem os mesmos índices.\n",
    "    are_all_index_equal = all(df.index.equals(data_list[0].index) for df in data_list)\n",
    "    \n",
    "    # Retorna um erro caso as séries temporais possuam índices diferentes.\n",
    "    if not are_all_index_equal:\n",
    "        raise ValueError(\"Todos as séries temporais devem possuir os mesmos índices.\")\n",
    "    \n",
    "    # Verifica se todas as séries temporais presentes na variável \"data_list\" possuem o atributo \"name\".\n",
    "    all_time_series_have_names = all(hasattr(df,\"name\") for df in data_list)\n",
    "    \n",
    "    # Retorna um erro caso uma das séries temporais presentes na variável \"data_list\" não possua o atributo \"name\".\n",
    "    if not all_time_series_have_names:\n",
    "        raise TypeError(\"Todas as séries temporais devem possuir o atributo 'name'\")\n",
    "    \n",
    "    # Cria uma lista de timestamps que representará o eixo x do gráfico que será plotado.\n",
    "    x_axis = data_list[0].index.tolist() # Observe que só podemos fazer isso pois temos certeza que todas as séries temporais possuem os mesmos índices.\n",
    "    # Cria a figura onde será plotado o gráfico.\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Adiciona cada série temporal ao gráfico.\n",
    "    for time_serie in data_list:\n",
    "        # Plota o gráfico (Data x Valor da Ação) do ticker em questão.\n",
    "        fig.add_trace(go.Scatter(x=x_axis, y=time_serie.values, mode=\"lines\", name=time_serie.name))\n",
    "    \n",
    "    # Atualiza o layout para permitir destaque ao clicar na legenda.\n",
    "    fig.update_layout(\n",
    "        # Seta um título para o plot.\n",
    "        title=serie_title,\n",
    "        # Seta um título para o eixo x do plot.\n",
    "        xaxis_title=serie_xaxis_title,\n",
    "        # Seta um título para o eixo y do plot.\n",
    "        yaxis_title=serie_yaxis_title,   \n",
    "    )\n",
    "    \n",
    "    # Exibe o gráfico criado.\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = {\n",
    "    #\n",
    "    \"monthly_results_sheets\": ['resultados_portfolio_mensal_full_1.xlsx', 'resultados_portfolio_mensal_full_2.xlsx',\n",
    "                               'resultados_portfolio_mensal_full_3.xlsx', 'resultados_portfolio_mensal_full_4.xlsx'],\n",
    "    #\n",
    "    \"weekly_results_sheets\": ['resultados_portfolio_semanal_full_1.xlsx']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file_and_get_results(filename: str) -> pd.DataFrame:\n",
    "    '''\n",
    "        Description:\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Return:\n",
    "    '''\n",
    "\n",
    "    # Ler todas as planilhas do arquivo Excel\n",
    "    dfs = pd.read_excel(filename, sheet_name=None)\n",
    "    \n",
    "    #\n",
    "    first_trading_day = dfs['Período 1'][dfs['Período 1'].columns[0]][0].split(\" - \")[0]\n",
    "    #\n",
    "    first_trading_day = np.datetime64(first_trading_day)\n",
    "    \n",
    "    #\n",
    "    results = pd.DataFrame({\n",
    "        \"Retorno\": 0\n",
    "    }, index=[first_trading_day])\n",
    "    \n",
    "    # Acessar e trabalhar com cada DataFrame\n",
    "    for period, df in dfs.items():\n",
    "        if not df.empty:\n",
    "            #\n",
    "            period_last_trading_day = df[df.columns[0]][0].split(\" - \")[1]\n",
    "            #\n",
    "            period_last_trading_day = np.datetime64(period_last_trading_day)\n",
    "            #\n",
    "            tickers_to_trade = math.ceil(df.shape[0]*0.1)\n",
    "            #\n",
    "            period_return = df.iloc[:tickers_to_trade]['Retorno Real'].mean() # Trocar por um .sum() ?\n",
    "            #\n",
    "            result = pd.DataFrame({\n",
    "                \"Retorno\": period_return,\n",
    "            },index=[period_last_trading_day])\n",
    "            #\n",
    "            results = pd.concat([results, result])\n",
    "    \n",
    "    return results\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_file_and_get_results(setup['weekly_results_sheets'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sugestões**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gŕaficos a serem feitos:** *(Ver em quais gráficos deve ser plotada uma região de confiança)*\n",
    "\n",
    "    - Gráfico de série temporal com o maior retorno acumulado, menor retorno acumulado e retorno médio acumulado da estratégia.\n",
    "  \n",
    "    - Gráfico de série temporal com o retorno médio acumulado da estratégia (logarítmico) x retorno médio acumulado do S&P500 (logarítmico).\n",
    "  \n",
    "    - Gráfico de série temporal com o retorno médio por período da estratégia x sharpe ratio por período da estratégia x sortino ratio por  período da estratégia.\n",
    "  \n",
    "    - Histograma com a distribuição dos retornos médios por período da estratégia *(plotar sobre os histogramas uma linha de distribuição normal ajustada)*. Para esse histograma, é importante calcular a assimetria (quanto mais próximo de 0, mais \"normal\" é a distribuição) e a kurtosis (quanto mais próximo de 3, mais \"normal\" é a distribuição).\n",
    "  \n",
    "    - Gráfico de barras com os retornos médios por período da estratégia x retornos por período do S&P 500."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
