{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Instalando as bibliotecas que serão necessárias*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/user/.local/lib/python3.10/site-packages (2.0.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/user/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/user/.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/user/.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /home/user/.local/lib/python3.10/site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Instala a biblioteca \"pandas\" que será usada para manipulação de dados.\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy in /home/user/.local/lib/python3.10/site-packages (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "# Instala a biblioteca \"numpy\" que será usada para operações numéricas.\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in /home/user/.local/lib/python3.10/site-packages (4.66.4)\n"
     ]
    }
   ],
   "source": [
    "# Instala a biblioteca \"tqdm\" que será usada para a exibição de barras de carregamento.\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/user/.local/lib/python3.10/site-packages (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/user/.local/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/user/.local/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/user/.local/lib/python3.10/site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/user/.local/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n"
     ]
    }
   ],
   "source": [
    "# Instala a biblioteca \"scikit-learn\" que será usada para escalonamento das features.\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Importando as bibliotecas que serão necessárias*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-07 21:42:46.421586: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 21:42:46.685845: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-07 21:42:46.929111: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-07 21:42:47.114450: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-07 21:42:47.167915: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-07 21:42:47.522065: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 21:42:50.592436: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Importa a biblioteca \"pandas\", que será usada para manipulação de dados.\n",
    "import pandas as pd\n",
    "\n",
    "# Importa a biblioteca \"numpy\", que será usada para operações numéricas.\n",
    "import numpy as np\n",
    "\n",
    "# Importa o módulo log da biblioteca \"math\" para realizar cálculos envolvendo logarítmos na base e.\n",
    "from math import log\n",
    "\n",
    "# Importa a classe Ticker da \"biblioteca\" Ticker para lidar com ativos financeiros. \n",
    "from Ticker import Ticker\n",
    "\n",
    "# Importa a classe Tickers da \"biblioteca\" Tickers para lidar com um conjunto de ativos financeiros.\n",
    "from Tickers import Tickers\n",
    "\n",
    "# Importa a classe Model da \"biblioteca\" Model para lidar com redes neurais do tipo LSTM.\n",
    "from Model import Model\n",
    "\n",
    "# Importa o módulo datetime da biblioteca datetime para lidar com datas.\n",
    "from datetime import datetime\n",
    "\n",
    "# Importa a biblioteca \"tqdm\", que será usada para a exibição de barras de carregamento.\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Importa o módulo MinMaxScaler da biblioteca \"sklearn\", que será utilizado para realizar a \"desnormalização\" \n",
    "# das variáveis target que foram usadas no modelo LSTM.\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Obtendo a lista de tickers do S&P500*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Essa célula será usada para se obter os tickets das companhias que fazem parte do S&P 500, com base em dados da wikipedia.\n",
    "'''\n",
    "\n",
    "# Salva em uma variável a url que contém a tabela com os tickets das companhias.\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "\n",
    "# Lê todas as tabelas presentes na url acima.\n",
    "sp500_table = pd.read_html(url)\n",
    "\n",
    "# Salva a coluna \"Symbol\" da primeira tabela em uma variável (tal coluna contém todos os tickets das companhias que fazem parte do S&P 500).\n",
    "sp500_symbols= sp500_table[0]['Symbol']\n",
    "\n",
    "# Transforma os tickets obtidos em uma lista.\n",
    "sp500_symbols = sp500_symbols.tolist()\n",
    "\n",
    "# Exibe a lista de tickets criada acima.\n",
    "#sp500_symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Definindo alguns parâmetros que serão importantes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Essa célula será usada para criar um dicionário chamado setup, que contém os parâmetros principais que este código necessita. \n",
    "'''\n",
    "\n",
    "# Cria um dicionário para armazenar os parâmetros principais do modelo, garantindo flexibilidade e fácil modificação desses valores.\n",
    "setup = {\n",
    "    \n",
    "    # Lista dos símbolos das ações que serão utilizadas para a coleta de dados e previsões.\n",
    "    \"symbols\": sp500_symbols,\n",
    "    \n",
    "    # Data inicial para a extração de dados (Deve obrigatoriamente ser um dia de negociação).\n",
    "    \"data_extraction_initial_date\": datetime(2019,1,2).date(), #  Primeiro dia de negociações do S&P500 em 2019.\n",
    "    \n",
    "    # Data final cujos dados serão coletados (Deve obrigatoriamente ser um dia de negociação e \n",
    "    # deve também obrigatoriamente suceder um dia de negociação.).\n",
    "    \"data_extraction_final_date\": datetime(2023,12,30).date(), #(Último dia de negociações do S&P500 em 2023). \n",
    "    \n",
    "    # Período da estratégia a ser usada: define a frequência para a análise dos retornos (Ex.: 5 para análise semanal, 20 para mensal).\n",
    "    \"strategy_time_period\": 20, # Observação: São levados em conta como dias na estratégia apenas aqueles onde ocorreram negociações.\n",
    "    \n",
    "    # Limite mínimo de probabilidade para que um ativo seja considerado em regime de baixa volatilidade e, portanto, \n",
    "    # elegível para negociação no período em questão. Somente ativos cuja probabilidade média de baixa volatilidade \n",
    "    # exceda esse valor serão considerados negociáveis.\n",
    "    \"regime_probability_threshold\": 0.9,\n",
    "    \n",
    "    # Quantidade máxima de ativos que poderão compor o portfólio em cada período.\n",
    "    \"number_of_tickets_to_be_selected\": 50,\n",
    "    \n",
    "    # Define os períodos de tempo (janelas móveis) para o cálculo das principais features técnicas a serem usadas no modelo.\n",
    "    \"features_time_period\": {\n",
    "        # Define o período (janela móvel) para o cálculo dos retornos.\n",
    "        \"returns_time_period\": 1,\n",
    "        # Define o período (janela móvel) para o cálculo da média móvel exponencial.\n",
    "        \"exponential_moving_average_time_period\": 14,\n",
    "        # Define o período (janela móvel) para o cálculo do Índice de Força Relativa (RSI).\n",
    "        \"relative_strength_index_time_period\": 14,\n",
    "        # Define o período (janela móvel) para o cálculo da Faixa Média Verdadeira (ATR).\n",
    "        \"average_true_range_time_period\": 14,\n",
    "        # Define o período (janela móvel) para o cálculo do momentum.\n",
    "        \"momemtum_time_period\": 14,\n",
    "        # Frequência para coleta dos dados do VIX. O valor \"1d\" indica que os dados do VIX serão registrados \n",
    "        # em intervalos diários de negociação.\n",
    "        \"vix_time_period\": \"1d\",\n",
    "        # Define o período para o cálculo das mudanças percentuais (Usado no vix e no MSGARCH).\n",
    "        \"pct_change_period\": 1,\n",
    "    },\n",
    "    # Define o comprimento das sequências de tempo (janelas móveis) usadas no modelo LSTM.\n",
    "    \"lstm_time_sequences_length\": 3,\n",
    "    #\n",
    "    \"output_file_name\": \"resultados_portfolio_mensal_full_5.xlsx\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Obtendo os dados dos tickers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "779a1b95199347fd919d79d2016fde93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Baixando e processando os tickers:   0%|          | 0/503 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$BF.B: possibly delisted; No price data found  (1d 2019-01-02 -> 2023-12-30)\n"
     ]
    }
   ],
   "source": [
    "# Inicializa o objeto `tickers` com os parâmetros principais definidos no dicionário `setup`, incluindo símbolos das ações,\n",
    "# datas de início e fim para extração de dados, períodos de cálculo das features, frequência da estratégia, \n",
    "# limite de probabilidade de regime e número de ativos selecionados.\n",
    "\n",
    "# Todos os tickers presentes no objeto `tickers` terão os dados padronizados, ou seja, estarão alinhados com os mesmos índices de data,\n",
    "# garantindo consistência temporal para cálculos e análises posteriores.\n",
    "\n",
    "tickers = Tickers(setup['symbols'], setup['data_extraction_initial_date'], setup['data_extraction_final_date'],\n",
    "                  setup['features_time_period'], setup['strategy_time_period'],\n",
    "                  setup['regime_probability_threshold'], setup['number_of_tickets_to_be_selected'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Criando o modelo LSTM*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula o número de features (colunas de dados) a serem utilizadas como entrada no modelo, subtraindo 1 para excluir a coluna do target.\n",
    "features_number = (tickers.symbols[0].data.shape[1] - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma instância do modelo LSTM, passando o número de features e o comprimento das sequências de tempo (janelas temporais) para \n",
    "# preparar o modelo.\n",
    "model = Model(features_number,setup['lstm_time_sequences_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrói a arquitetura da rede LSTM, configurando as camadas e os parâmetros necessários para o treinamento do modelo.\n",
    "model.create_LSTM_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Obtendo e salvando as predições*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_period_results(ticker: Ticker, predicted: pd.Series, period_initial_date: datetime.date, period_final_date: datetime.date) -> pd.DataFrame: \n",
    "    '''\n",
    "        Description:\n",
    "            Calcula e armazena os resultados de retorno predito e real para um ativo específico (`ticker`) em um período determinado.\n",
    "            A função aplica a transformação inversa aos valores escalados (real e predito), calcula os retornos logarítmicos\n",
    "            e retorna os resultados em um DataFrame.\n",
    "        Args:\n",
    "            ticker (Ticker): Objeto do tipo Ticker que contém dados e informações relevantes do ativo.\n",
    "            predicted (pd.Series): Série temporal contendo os valores preditos do preço do ativo.\n",
    "            period_initial_date (datetime.date): Data inicial do período de análise.\n",
    "            period_final_date (datetime.date): Data final do período de análise.\n",
    "        Return:\n",
    "            pd.DataFrame: DataFrame com os resultados de retorno real e predito para o período especificado, \n",
    "                          contendo o símbolo da ação, retorno predito e retorno real.\n",
    "    '''\n",
    "    \n",
    "    # Redimensiona y_train para que ele seja bidimensional (Necessário para o MinMaxScaler).\n",
    "    resized_y_train = ticker.__y_train__.values.reshape(-1, 1)  \n",
    "\n",
    "    # Cria uma instancia do MinMaxScaler para o target do ticker em questão.\n",
    "    scaler_target = MinMaxScaler()\n",
    "\n",
    "    # Ajusta a instância criada acima ao conjunto de treino do target do ticker em questão.\n",
    "    scaler_target.fit_transform(resized_y_train)\n",
    "\n",
    "    # Volta os valores de \"y_test_scaled_sequences\" para a escala normal e associa a esses valores as suas datas originais, criando assim\n",
    "    # uma série temporal.\n",
    "    real_y = pd.Series(scaler_target.inverse_transform(ticker.__y_test_scaled_sequences__).flatten(),\n",
    "                    index= ticker.__y_test__.index[len(ticker.__y_test__) - len(ticker.__y_test_scaled_sequences__):]\n",
    "    )\n",
    "    \n",
    "    # Adiciona um nome a série temporal \"real_y\".\n",
    "    real_y.name = f\"Preço real de {ticker.symbol}\" # Útil para eventuais gráficos.\n",
    "\n",
    "    # Volta os valores estimados para a escala normal e associa a esses valores as suas datas originais, criando assim\n",
    "    # uma série temporal.\n",
    "    predicted_y = pd.Series(\n",
    "        scaler_target.inverse_transform(predicted).flatten(),\n",
    "        index=ticker.__y_test__.index[len(ticker.__y_test__) - len(ticker.__y_test_scaled_sequences__):]\n",
    "    )\n",
    "\n",
    "    # Calcula o retorno predito e o retorno real como retornos logarítmicos e os salva no DataFrame results, juntamente do symbol do ticker.\n",
    "    results = {\n",
    "        \"Ação\": ticker.symbol,\n",
    "        \"Retorno Predito\": log(predicted_y[-1]/predicted_y[0]) * 100,\n",
    "        \"Retorno Real\": log(real_y[-1]/real_y[0]) * 100\n",
    "    }\n",
    "\n",
    "    # Define os índices do DataFrame para o período analisado. Tais índices estarão no formato \"data inicial - data final\".\n",
    "    index = [str(period_initial_date) + \" - \" + str(period_final_date)]\n",
    "    \n",
    "    return pd.DataFrame(results, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_period(tickers: Tickers, tickers_to_trade:list, period_number:int, strategy_time_period: int, indexes: list, model) -> pd.DataFrame:\n",
    "    '''\n",
    "        Description:\n",
    "            Processa os resultados do modelo para um certo período de negociação e um certo conjunto de tickers selecionados. \n",
    "            Para cada ticker, prepara os dados, treina o modelo e obtém as previsões para o período especificado.\n",
    "            Retorna um DataFrame com os resultados de retorno predito e real, ordenados pelo retorno predito.\n",
    "        Args:\n",
    "            tickers (Tickers): Objeto contendo informações e dados históricos de todos os ativos.\n",
    "            tickers_to_trade (list): Lista de índices dos symbols presentes na variável tickers que serão negociados no período atual.\n",
    "            period_number (int): Número do período atual que está sendo processado.\n",
    "            strategy_time_period (int): Período de tempo da estratégia em dias (usado para definir a janela de negociação).\n",
    "            indexes (list): Lista de datas que representam os dias de negociação.\n",
    "            model: Instância do modelo LSTM que será treinado e usado para previsões.\n",
    "        Return:\n",
    "            pd.DataFrame: DataFrame contendo os resultados dos retornos preditos e reais para os tickers negociados no período,\n",
    "                          ordenados pelo retorno predito em ordem decrescente.\n",
    "    '''\n",
    "    \n",
    "    # Define a data inicial do período atual a partir da lista de índices (indexes), multiplicando o número do período pelo tempo da estratégia.\n",
    "    period_initial_date = indexes[strategy_time_period*period_number].date()\n",
    "    # Define a data final do período atual a partir da lista de índices (indexes).\n",
    "    period_final_date = indexes[strategy_time_period*period_number - 1 + strategy_time_period].date()\n",
    "    \n",
    "    # Inicializa um DataFrame vazio para armazenar os resultados do período atual.\n",
    "    period_results = pd.DataFrame()\n",
    "    \n",
    "    # Itera sobre cada ticker na lista de tickers a serem negociados para o período.\n",
    "    for ticker_index in tickers_to_trade: \n",
    "        \n",
    "        # Prepara os dados do ticker em questão para o modelo LSTM, gerando sequências normalizadas de treino e teste.\n",
    "        X_train_scaled_sequences, X_test_scaled_sequences, y_train_scaled_sequences, y_test_scaled_sequences = \\\n",
    "        tickers.symbols[ticker_index].prepare_data_for_lstm(period_initial_date,period_final_date,setup['lstm_time_sequences_length'])\n",
    "        \n",
    "        # Treina o modelo com os dados de treino e obtém as previsões para os dados de teste, junto com o erro quadrático médio do modelo.\n",
    "        predicted, RMSE = model.train_model_and_get_results(\n",
    "            X_train_scaled_sequences,X_test_scaled_sequences,y_train_scaled_sequences,y_test_scaled_sequences)\n",
    "        \n",
    "        # Calcula e armazena os retornos preditos e reais para o ticker no período atual.\n",
    "        period_results = pd.concat([period_results,get_ticker_period_results(\n",
    "            tickers.symbols[ticker_index], predicted, period_initial_date, period_final_date)])\n",
    "    \n",
    "    # Ordena o DataFrame dos resultados pelo retorno predito em ordem decrescente.\n",
    "    period_results = period_results.sort_values(by=\"Retorno Predito\", ascending=False)\n",
    "        \n",
    "    return period_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_periods_and_save_results(tickers: Tickers, tickers_to_trade: list, periods_number: int, \n",
    "                                     indexes: list, model: Model, strategy_time_period: int, output_file_name: str) -> None:\n",
    "    \"\"\"\n",
    "        Description:     \n",
    "            Processa os resultados do modelo para uma certa quantidade de períodos de negociação e um certo conjunto de tickers \n",
    "            selecionados para cada período. Após isso, salva tais resultados em um arquivo Excel.\n",
    "        Args:\n",
    "            tickers (Tickers): Objeto contendo informações e dados históricos de todos os ativos.\n",
    "            tickers_to_trade (list): Lista de índices dos symbols presentes na variável tickers que serão negociados no período atual.\n",
    "            periods_number (int): Número total de períodos a serem processados.\n",
    "            indexes (list): Lista de datas que representam os dias de negociação.\n",
    "            model: Instância do modelo LSTM que será treinado e usado para previsões.\n",
    "            strategy_time_period (int): Período de tempo da estratégia em dias (usado para definir a janela de negociação).\n",
    "            output_file_name (str): Nome do arquivo de saída onde os resultados serão salvos.\n",
    "        Return:\n",
    "            Essa função não retorna nada, mas salva os resultados obtidos para os períodos em questão em um arquivo .xlsx.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Inicializa uma lista para armazenar os resultados de cada período de negociação.\n",
    "    results = []\n",
    "\n",
    "    # Itera sobre o intervalo de períodos de negociação, com uma barra de progresso para monitorar o progresso da iteração.\n",
    "    for period in tqdm(range(1, periods_number), desc=\"Processando os períodos\", unit=\"período\"):\n",
    "        print(f\"\\nProcessando o período {period}...\\n\")\n",
    "        \n",
    "        # Verifica se existem tickers disponíveis para negociação no período atual.\n",
    "        if tickers_to_trade[period] != []:\n",
    "            # Se houver tickers para negociar, processa o período utilizando a função 'process_period'.\n",
    "            period_results = process_period(tickers, tickers_to_trade[period], period, strategy_time_period, indexes, model)\n",
    "            \n",
    "            # Adiciona os resultados do período processado à lista de resultados.\n",
    "            results.append(period_results)\n",
    "        else:\n",
    "            # Se não houver tickers para negociar, adiciona um DataFrame vazio na lista de resultados.\n",
    "            results.append(pd.DataFrame())\n",
    "\n",
    "    # Cria um arquivo Excel para salvar os resultados de todos os períodos.\n",
    "    with pd.ExcelWriter(output_file_name) as writer:\n",
    "        # Itera sobre os resultados e salva cada período em uma aba do Excel.\n",
    "        for period, period_results in enumerate(results):\n",
    "            # Define o nome da aba baseado no número do período.\n",
    "            sheet_name = f'Período {period+1}'  \n",
    "    \n",
    "            # Salva o DataFrame do período na aba correspondente.\n",
    "            period_results.to_excel(writer, sheet_name=sheet_name)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula o número total de períodos de negociação que serão analisados. Para tal, é dividido o número total de dados \n",
    "# pelo período de tempo da estratégia.\n",
    "periods_number = (tickers.symbols[0].data.shape[0] // setup['strategy_time_period'])\n",
    "\n",
    "# Extrai o índice de datas dos dados históricos do primeiro ticker (aqui podemos assumir que todos os tickers têm o mesmo índice de datas).\n",
    "indexes = tickers.symbols[0].data.index\n",
    "\n",
    "# Obtém a lista de tickers a serem negociados para o período atual.\n",
    "tickers_to_trade = tickers.get_tickers_to_trade()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando os períodos:   0%|          | 0/2 [00:00<?, ?período/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando o período 1...\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando os períodos:  50%|█████     | 1/2 [01:48<01:48, 108.59s/período]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processando o período 2...\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando os períodos: 100%|██████████| 2/2 [03:29<00:00, 104.74s/período]\n"
     ]
    }
   ],
   "source": [
    "# Chama a função 'process_periods_and_save_results' para processar, para todos os períodos, os resultados obtidos através do modelo criado.\n",
    "process_periods_and_save_results(tickers, tickers_to_trade, periods_number, indexes, \n",
    "                                 model, setup['strategy_time_period'],setup['output_file_name'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
