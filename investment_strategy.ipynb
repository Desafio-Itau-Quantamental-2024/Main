{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Configurando as bibliotecas do projeto**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Instalação de bibliotecas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: Ta-Lib in /home/user/.local/lib/python3.10/site-packages (0.4.32)\n",
      "Requirement already satisfied: numpy in /home/user/.local/lib/python3.10/site-packages (from Ta-Lib) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "# Instala a biblioteca \"TA-Lib\" que será responsável por fornecer a implementação de alguns indicadores técnicos.\n",
    "!pip install Ta-Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /home/user/.local/lib/python3.10/site-packages (2.17.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (2.17.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: packaging in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (1.66.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (1.24.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (4.25.4)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (4.10.0)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (3.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: optree in /home/user/.local/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: namex in /home/user/.local/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: rich in /home/user/.local/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (13.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/user/.local/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/user/.local/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/user/.local/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/user/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/user/.local/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/user/.local/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/user/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "# Instala a biblioteca \"tensorflow\" que será responsável por fornecer a implementação dos métodos necessários para a construção da LSTM.\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Importação de bibliotecas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Essa célula será usada para a importação de bibliotecas.\n",
    "'''\n",
    "\n",
    "# Importa a biblioteca que será utilizada para a obtenção dos dados financeiros.\n",
    "import yfinance as yf\n",
    "# Importa a biblioteca que será utilizada para a manipulação de DataFrames.\n",
    "import pandas as pd\n",
    "# Importa o módulo da biblioteca \"datetime\" que será utilizada para lidar com objetos do tipo \"datetime\".\n",
    "from datetime import datetime, timedelta\n",
    "# Importa o módulo da biblioteca \"typing\" que será utilizado para tipar parâmetros opcionais de funções.\n",
    "from typing import Optional\n",
    "# Importa a biblioteca que será utilizada para a manipulação de arrays e também para o uso de algumas funções matemáticas.\n",
    "import numpy as np\n",
    "# Importa a biblioteca que será utilizada para calcular algumas métricas de análise técnica.\n",
    "import talib\n",
    "# Importa o módulo da biblioteca \"sklearn\" que será utilizado para escalar as features dos DataFrames que serão usados no modelo LSTM.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Importa um dos módulos da biblioteca \"tensorflow\" que será utilizado para criar o modelo LSTM. \n",
    "from tensorflow.keras.models import Sequential\n",
    "# Importa um dos módulos da biblioteca \"tensorflow\" que será utilizado para construir as camadas que farão parte da arquitetura do modelo LSTM \n",
    "# a ser usado. \n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "# Importa a biblioteca que será utilizada para criar gráficos interativos.\n",
    "import plotly.graph_objects as go\n",
    "# Importa a função \"mean_squared_error\" da biblioteca sklearn.metrics.\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Definindo a classe Ticker**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ticker:\n",
    "    '''\n",
    "        Description:\n",
    "            A classe \"Ticker\" representa um ativo financeiro identificado por um símbolo único (ticker). \n",
    "            Ela é responsável por baixar os dados históricos de preços e calcular vários indicadores técnicos, \n",
    "            como retornos aritméticos e logarítmicos, Bandas de Bollinger, RSI (Índice de Força Relativa), \n",
    "            ATR (Average True Range) e Momentum. O objetivo principal da classe é fornecer um conjunto padronizado de dados \n",
    "            e indicadores para análise de ativos financeiros. Além disso, valida se os dados extraídos estão de acordo com \n",
    "            o período solicitado e prepara os dados para uso posterior, como em modelos de aprendizado de máquina.\n",
    "    '''\n",
    "    \n",
    "    def __is_ticker_valid__(self) -> bool:\n",
    "        '''\n",
    "            Description:\n",
    "                Verifica se o ticker é considerado válido. Um ticker será considerado válido quando:\n",
    "                - O atributo `data` não for vazio.\n",
    "                - O índice inicial do atributo `data` corresponder à data de extração inicial (`data_extraction_initial_date`).\n",
    "                - O índice final do atributo `data` corresponder à data de extração final (`data_extraction_final_date` - 1 dia).\n",
    "            \n",
    "            Args:\n",
    "                Nenhum argumento é passado diretamente para esta função, pois ela usa os atributos do objeto \n",
    "                (`self.data`, `self.data_extraction_initial_date`, etc.).\n",
    "\n",
    "            Return:\n",
    "                bool: Retorna `True` se o ticker for considerado válido de acordo com as condições definidas, caso contrário retorna `False`.\n",
    "        '''\n",
    "        \n",
    "        # Verifica se o atributo data é vazio.\n",
    "        if(len(self.data) == 0): return False\n",
    "        \n",
    "        # Verifica se a data inicial do índice do DataFrame corresponde à data de extração inicial.\n",
    "        condition_2 = (self.data.index[0].date() == self.data_extraction_initial_date)\n",
    "        # Verifica se a data final do índice do DataFrame corresponde à data de extração final - 1 dia.\n",
    "        condition_3 = (self.data.index[len(self.data.index)-1].date() == self.data_extraction_final_date - timedelta(days=1))\n",
    "        \n",
    "        # Observação: Irá ocorrer problemas com as condições acima caso self.data_extraction_initial_date ou self.data_extraction_final_data \n",
    "        # não sejam dias de negociação. Visto que, caso isso ocorra, tais condições serão falsas e consequentemente o Ticker em questão \n",
    "        # não será considerado válido.\n",
    "        \n",
    "        # Retorna False se alguma das condições não for satisfeita.\n",
    "        if(not(condition_2) or not(condition_3)):\n",
    "            return False\n",
    "        \n",
    "        # Retorna True caso contrário (se todas as condições forem satisfeitas).\n",
    "        return True\n",
    "        \n",
    "        \n",
    "    def __get_ticker_data__(self) -> pd.DataFrame:\n",
    "        '''\n",
    "            Description:\n",
    "                Baixa os dados do ticker usando a biblioteca `yfinance` para o período de tempo definido pelos atributos \n",
    "                `data_extraction_initial_date` e `data_extraction_final_date`.\n",
    "                \n",
    "            Args:\n",
    "                Nenhum argumento é passado diretamente para esta função, pois ela utiliza os atributos do objeto \n",
    "                (`self.symbol`, `self.data_extraction_initial_date`, etc.).\n",
    "            \n",
    "            Return:\n",
    "                pd.DataFrame: Um DataFrame contendo os dados históricos do ticker para o período solicitado. \n",
    "                Retorna um DataFrame vazio se ocorrer algum erro.\n",
    "        '''\n",
    "        \n",
    "        try:\n",
    "            # Faz o download dos dados do ticker em questão.\n",
    "            return yf.download(self.symbol, \n",
    "                               start=self.data_extraction_initial_date, \n",
    "                               end=self.data_extraction_final_date)\n",
    "        except Exception as e:  \n",
    "            # Captura e imprime a exceção caso ocorra um erro ao baixar os dados.\n",
    "            print(f\"Erro ao baixar os dados para {self.symbol}: {e}\")\n",
    "            # Retorna um DataFrame vazio em caso de erro.\n",
    "            return pd.DataFrame()  \n",
    "        \n",
    "    def __get_arithmetic_returns__(self) -> pd.Series:\n",
    "        '''\n",
    "            Description:\n",
    "                Calcula os retornos aritméticos baseados nos preços ajustados de fechamento (Adj Close).\n",
    "                O retorno aritmético mede a variação percentual do preço de fechamento ajustado em relação ao período anterior.\n",
    "                \n",
    "            Args:\n",
    "                Nenhum argumento é passado diretamente, pois a função utiliza os atributos do objeto.\n",
    "            \n",
    "            Return:\n",
    "                pd.Series: Uma série com os retornos aritméticos para o período definido, divididos por 100 para normalizar os valores.\n",
    "        '''\n",
    "        \n",
    "        # Obtém os preços ajustados de fechamento.\n",
    "        daily_prices = self.data['Adj Close']\n",
    "\n",
    "        # Calcula os retornos aritméticos usando o método ROC da talib.\n",
    "        arithmetic_returns = talib.ROC(daily_prices, timeperiod=self.__features_time_period__['returns_time_period']) \n",
    "        \n",
    "        # Normaliza os retornos dividindo por 100 (ROC retorna valores em percentual).\n",
    "        return (arithmetic_returns/100)\n",
    "    \n",
    "    def __get_logarithmic_returns__(self) -> pd.Series:\n",
    "        '''\n",
    "            Description:\n",
    "                Calcula os retornos logarítmicos baseados nos retornos aritméticos. \n",
    "                O retorno logarítmico é uma medida que transforma os retornos aritméticos em uma forma que facilita a análise estatística e \n",
    "                agregação de múltiplos retornos.\n",
    "            \n",
    "            Args:\n",
    "                Nenhum argumento é passado diretamente, pois a função utiliza os atributos do objeto.\n",
    "            \n",
    "            Return:\n",
    "                pd.Series: Uma série com os retornos logarítmicos.\n",
    "        '''\n",
    "        \n",
    "        # Obtém os retornos aritméticos.\n",
    "        arithmetic_returns = self.__get_arithmetic_returns__()\n",
    "        \n",
    "        # Calcula os retornos logarítmicos aplicando a função log(1 + retorno aritmético).\n",
    "        logarithmic_returns = arithmetic_returns.apply(lambda x: np.log(1 + x))\n",
    "        \n",
    "        return logarithmic_returns\n",
    "    \n",
    "    def __get_bollinger_bands_with_exponential_moving_average__(self) -> pd.Series:\n",
    "        '''\n",
    "            Description:\n",
    "                Calcula as Bandas de Bollinger com base na média móvel exponencial dos preços ajustados de fechamento (Adj Close).\n",
    "                As Bandas de Bollinger são usadas para medir a volatilidade e identificar potenciais pontos de reversão de tendência.\n",
    "            \n",
    "            Args:\n",
    "                Nenhum argumento é passado diretamente, pois a função utiliza os atributos do objeto.\n",
    "            \n",
    "            Return:\n",
    "                Tuple[pd.Series, pd.Series, pd.Series]: Um tuple contendo três séries: a banda superior, a banda média (EMA) e a banda inferior.\n",
    "        '''\n",
    "        \n",
    "        # Obtém os preços ajustados de fechamento.\n",
    "        daily_prices = self.data['Adj Close']\n",
    "        \n",
    "        # Calcula as Bandas de Bollinger usando o talib.\n",
    "        upper_band, middle_band, lower_band = talib.BBANDS(daily_prices, \n",
    "                                                           timeperiod=self.__features_time_period__['exponential_moving_average_time_period'],\n",
    "                                                           nbdevup=2, nbdevdn=2, matype=1) # Tipo de média móvel: 1 é a média móvel exponencial.\n",
    "        \n",
    "        return upper_band, middle_band, lower_band\n",
    "        \n",
    "    def __get_relative_strength_index__(self) -> pd.Series:\n",
    "        '''\n",
    "            Description:\n",
    "                Calcula o Índice de Força Relativa (RSI) com base nos preços ajustados de fechamento (Adj Close).\n",
    "                O RSI é um indicador de momentum usado para identificar condições de sobrecompra ou sobrevenda de um ativo.\n",
    "            \n",
    "            Args:\n",
    "                Nenhum argumento é passado diretamente, pois a função utiliza os atributos do objeto.\n",
    "            \n",
    "            Return:\n",
    "                pd.Series: Uma série contendo os valores do RSI para o período definido.\n",
    "        '''\n",
    "        \n",
    "        # Obtém os preços ajustados de fechamento.\n",
    "        daily_prices = self.data['Adj Close']\n",
    "        \n",
    "        # Calcula o RSI usando o talib.\n",
    "        relative_strength_index = talib.RSI(daily_prices, timeperiod=self.__features_time_period__['relative_strength_index_time_period'])\n",
    "        \n",
    "        return relative_strength_index\n",
    "    \n",
    "    def __get_average_true_range__(self) -> pd.Series:\n",
    "        '''\n",
    "            Description:\n",
    "                Calcula o Average True Range (ATR) baseado nas séries de preços máximos, mínimos e de fechamento.\n",
    "                O ATR é um indicador de volatilidade que mede a variação média entre o preço máximo e o preço mínimo do período.\n",
    "            \n",
    "            Args:\n",
    "                Nenhum argumento é passado diretamente, pois a função utiliza os atributos do objeto.\n",
    "            \n",
    "            Return:\n",
    "                pd.Series: Uma série contendo os valores do ATR para o período definido.\n",
    "        '''\n",
    "        \n",
    "        # Obtém as séries de preços máximos, mínimos e de fechamento.\n",
    "        high_prices = self.data['High']\n",
    "        low_prices = self.data['Low']\n",
    "        close_prices = self.data['Close']\n",
    "        \n",
    "        # Calcula o ATR usando o talib.\n",
    "        average_true_range = talib.ATR(high_prices, low_prices, close_prices, timeperiod=self.__features_time_period__['average_true_range_time_period'])\n",
    "\n",
    "        return average_true_range\n",
    "    \n",
    "    def __get_momemtum__(self) -> pd.Series:\n",
    "        '''\n",
    "            Description:\n",
    "                Calcula o indicador de momentum baseado nos preços ajustados de fechamento (Adj Close).\n",
    "                O momentum mede a taxa de variação dos preços, indicando a velocidade e direção das mudanças de preços.\n",
    "            \n",
    "            Args:\n",
    "                Nenhum argumento é passado diretamente, pois a função utiliza os atributos do objeto.\n",
    "            \n",
    "            Return:\n",
    "                pd.Series: Uma série contendo os valores de momentum para o período definido.\n",
    "        '''\n",
    "        \n",
    "        # Obtém os preços ajustados de fechamento.\n",
    "        daily_prices = self.data['Adj Close']\n",
    "        \n",
    "        # Calcula o momentum usando o talib\n",
    "        momemtum = talib.MOM(daily_prices, timeperiod=self.__features_time_period__['momemtum_time_period'])\n",
    "\n",
    "        return momemtum\n",
    "        \n",
    "    \n",
    "    def __init__(self, symbol: str, data_extraction_initial_date: datetime.date , data_extraction_final_date: datetime.date,\n",
    "                 features_time_period: dict) -> None:\n",
    "        '''\n",
    "            Description:\n",
    "                Inicializa uma instância da classe \"Ticker\", definindo os parâmetros essenciais como o símbolo do ativo financeiro,\n",
    "                o período de extração de dados e os períodos de tempo utilizados para calcular indicadores financeiros. Durante a inicialização,\n",
    "                os dados do ticker são baixados e validados.\n",
    "\n",
    "            Args:\n",
    "                symbol (str): O símbolo do ativo financeiro (ticker) cujos dados históricos serão extraídos.\n",
    "                data_extraction_initial_date (datetime.date): A data inicial para a extração dos dados.\n",
    "                data_extraction_final_date (datetime.date): A data final para a extração dos dados.\n",
    "                features_time_period (dict): Um dicionário que contém os parâmetros de tempo para o cálculo dos indicadores financeiros, \n",
    "                                            como RSI, Bandas de Bollinger, etc.\n",
    "            \n",
    "            Return:\n",
    "                None: O construtor não retorna nada, mas prepara a instância para que os dados e indicadores possam ser utilizados posteriormente.\n",
    "        '''\n",
    "        \n",
    "        # Define o símbolo do ticker.\n",
    "        self.symbol = symbol\n",
    "        \n",
    "        # Define a data inicial para extração dos dados.\n",
    "        self.data_extraction_initial_date = data_extraction_initial_date\n",
    "        \n",
    "        # Define a data final para extração dos dados.\n",
    "        self.data_extraction_final_date = data_extraction_final_date\n",
    "        \n",
    "        # Define os períodos de tempo para calcular os indicadores financeiros.\n",
    "        self.__features_time_period__ = features_time_period\n",
    "        \n",
    "        # Baixa os dados do ticker.\n",
    "        self.data = self.__get_ticker_data__()\n",
    "        \n",
    "        # Verifica se o ticker é válido.\n",
    "        self.is_valid = self.__is_ticker_valid__()\n",
    "    \n",
    "    def __set_features__(self) -> None:\n",
    "        '''\n",
    "            Description:\n",
    "                Calcula e adiciona alguns indicadores financeiros como colunas ao DataFrame 'data' da instância. \n",
    "                Esses indicadores incluem retornos logarítmicos, Bandas de Bollinger com média móvel exponencial, RSI, ATR e Momentum.\n",
    "            \n",
    "            Args:\n",
    "                Nenhum argumento é passado diretamente, pois a função utiliza os atributos do objeto.\n",
    "            \n",
    "            Return:\n",
    "                None: A função não retorna nada, mas modifica o DataFrame 'data' da instância.\n",
    "        '''\n",
    "        \n",
    "        # Adiciona os retornos logarítmicos ao DataFrame.\n",
    "        self.data['Log returns'] = self.__get_logarithmic_returns__()\n",
    "        \n",
    "        # Adiciona as Bandas de Bollinger (banda superior, EMA, banda inferior) ao DataFrame.\n",
    "        self.data['B. upper bands'], self.data['EMA'], self.data['B. lower bands'] = self.__get_bollinger_bands_with_exponential_moving_average__()\n",
    "        \n",
    "        # Adiciona o Índice de Força Relativa (RSI) ao DataFrame.\n",
    "        self.data['RSI'] = self.__get_relative_strength_index__()\n",
    "        \n",
    "        # Adiciona o Average True Range (ATR) ao DataFrame.\n",
    "        self.data['ATR'] = self.__get_average_true_range__()\n",
    "        \n",
    "        # Adiciona o indicador de Momentum ao DataFrame.\n",
    "        self.data['MOM'] = self.__get_momemtum__()\n",
    "    \n",
    "    def __remove_some_features__(self) -> None:\n",
    "        '''\n",
    "            Description:\n",
    "                Remove algumas colunas desnecessárias do DataFrame, especificamente as colunas 'Open', 'High', 'Low', e 'Close'.\n",
    "            \n",
    "            Args:\n",
    "                Nenhum argumento é passado diretamente, pois a função utiliza os atributos do objeto.\n",
    "            \n",
    "            Return:\n",
    "                None: A função não retorna nada, mas modifica o DataFrame 'data' da instância.\n",
    "        '''\n",
    "        \n",
    "        # Remove as colunas 'Open', 'High', 'Low' e 'Close' do DataFrame.\n",
    "        self.data.drop(columns=['Open','High','Low','Close'], inplace=True)\n",
    "        \n",
    "    def prepare_data(self) -> None:\n",
    "        '''\n",
    "            Description:\n",
    "                Prepara os dados do ticker, calculando e adicionando os indicadores financeiros (features) e realizando\n",
    "                a limpeza dos dados, caso o ticker seja válido. Este método é útil para garantir que o DataFrame 'data'\n",
    "                contenha as informações necessárias para análises subsequentes.\n",
    "            \n",
    "            Args:\n",
    "                Nenhum argumento é passado diretamente, pois a função utiliza os atributos do objeto.\n",
    "            \n",
    "            Return:\n",
    "                None: A função não retorna nada, mas modifica o DataFrame 'data' da instância ao adicionar indicadores e\n",
    "                remover colunas e linhas desnecessárias.\n",
    "        '''\n",
    "        \n",
    "        # Se o ticker for considerado válido:\n",
    "        if self.is_valid:\n",
    "            # Calcula e adiciona as features (indicadores financeiros) ao DataFrame.\n",
    "            self.__set_features__()\n",
    "            \n",
    "            # Remove algumas colunas que não serão necessárias.\n",
    "            self.__remove_some_features__()\n",
    "            \n",
    "            # Remove todas as linhas que contenham valores nulos (NaN) no DataFrame.\n",
    "            self.data.dropna(inplace=True)\n",
    "            \n",
    "    def train_test_split(self, test_initial_day: datetime.date, test_final_day: datetime.date) -> tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
    "        '''\n",
    "            Description:\n",
    "                Divide os dados em conjuntos de treino e teste com base nas datas fornecidas. As features (X) e o alvo (y) são separados\n",
    "                e divididos em dados de treino e teste.\n",
    "\n",
    "            Args:\n",
    "                test_initial_day (datetime.date): Data que define o início do período de teste.\n",
    "                test_final_day (datetime.date): Data que define o final do período de teste.\n",
    "\n",
    "            Return:\n",
    "                tuple: Retorna quatro elementos - X_train (features de treino), X_test (features de teste), y_train (alvo de treino) e y_test (alvo de teste).\n",
    "        '''\n",
    "        \n",
    "        # Separa as features (X) e o target (y).\n",
    "        X = self.data.drop(columns=['Adj Close'])\n",
    "        y = self.data['Adj Close']\n",
    "        \n",
    "        # Separa o conjunto de séries temporais das features em dados de treino e dados de teste.\n",
    "        X_train, X_test = X[X.index < test_initial_day], X[(X.index >= test_initial_day) & (X.index <= test_final_day)]\n",
    "        \n",
    "        # Separa a série temporal do target em dados de treino e dados de teste.\n",
    "        y_train, y_test = y[y.index < test_initial_day], y[(y.index >= test_initial_day) & (y.index <= test_final_day)]\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def scale_data(self, X_train: pd.DataFrame, X_test: pd.DataFrame, y_train: pd.Series, y_test: pd.Series) -> tuple[np.ndarray,np.ndarray,np.ndarray,np.ndarray]:\n",
    "        '''\n",
    "            Description:\n",
    "                Normaliza as features e o target tanto para os conjuntos de treino quanto de teste usando o MinMaxScaler. Além disso,\n",
    "                redimensiona o alvo (y) para uma matriz bidimensional antes da normalização.\n",
    "\n",
    "            Args:\n",
    "                X_train (pd.DataFrame): Conjunto de treino das features.\n",
    "                X_test (pd.DataFrame): Conjunto de teste das features.\n",
    "                y_train (pd.Series): Conjunto de treino do alvo.\n",
    "                y_test (pd.Series): Conjunto de teste do alvo.\n",
    "\n",
    "            Return:\n",
    "                tuple: Retorna quatro elementos - X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled.\n",
    "        '''\n",
    "        \n",
    "        # Cria uma instancia do MinMaxScaler para as features do ticker em questão.\n",
    "        scaler_features = MinMaxScaler()\n",
    "\n",
    "        # Ajusta a instância criada acima ao conjunto de treino das features do ticker em questão.\n",
    "        X_train_scaled = scaler_features.fit_transform(X_train)  \n",
    "\n",
    "        # Redimensiona y_train para que ele seja bidimensional (Necessário para o MinMaxScaler).\n",
    "        resized_y_train = y_train.values.reshape(-1, 1)  \n",
    "\n",
    "        # Cria uma instancia do MinMaxScaler para o target do ticker em questão.\n",
    "        scaler_target = MinMaxScaler()\n",
    "\n",
    "        # Ajusta a instância criada acima ao conjunto de treino do target do ticker em questão.\n",
    "        y_train_scaled = scaler_target.fit_transform(resized_y_train)  \n",
    "\n",
    "        # Normaliza o conjunto de teste das features do ticker em questão usando a instância que foi criada e ajustada aos dados de treino\n",
    "        # desse mesmo ticker.\n",
    "        X_test_scaled = scaler_features.transform(X_test)  \n",
    "\n",
    "        # Redimensiona y_test para que seja bidimensional (Necessário para o MinMaxScaler).\n",
    "        resized_y_test = y_test.values.reshape(-1, 1) \n",
    "\n",
    "        # Normaliza o conjunto de teste do target  do ticker em questão usando a instância que foi criada e ajustada aos dados de treino desse\n",
    "        # mesmo ticker.\n",
    "        y_test_scaled = scaler_target.transform(resized_y_test)\n",
    "        \n",
    "        return X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled\n",
    "    \n",
    "    def create_time_sequences_for_lstm(self, X_train_scaled: np.ndarray, X_test_scaled: np.ndarray, y_train_scaled: np.ndarray,\n",
    "                              y_test_scaled: np.ndarray, sequence_length: int) -> tuple[np.ndarray,np.ndarray,np.ndarray,np.ndarray]:\n",
    "        '''\n",
    "            Description:\n",
    "                Constrói sequências temporais a partir dos dados normalizados de treino e teste, criando janelas móveis\n",
    "                de tamanho 'sequence_length'. Essas sequências são necessárias para treinar uma LSTM.\n",
    "\n",
    "            Args:\n",
    "                X_train_scaled (np.ndarray): Conjunto de treino normalizado das features.\n",
    "                X_test_scaled (np.ndarray): Conjunto de teste normalizado das features.\n",
    "                y_train_scaled (np.ndarray): Conjunto de treino normalizado do alvo.\n",
    "                y_test_scaled (np.ndarray): Conjunto de teste normalizado do alvo.\n",
    "                sequence_length (int): O comprimento das sequências temporais usadas para treinar a LSTM.\n",
    "\n",
    "            Return:\n",
    "                tuple: Retorna quatro elementos - X_train_scaled_sequences, X_test_scaled_sequences, \n",
    "                    y_train_scaled_sequences, y_test_scaled_sequences (sequências temporais normalizadas para treino e teste).\n",
    "        '''\n",
    "    \n",
    "        # Verifica se o sequence_length é maior que o número de amostras disponíveis\n",
    "        if sequence_length > len(X_train_scaled):\n",
    "            raise ValueError(\"O 'sequence_length' não pode ser maior que o número de amostras em 'X_train_scaled'.\")\n",
    "        if sequence_length > len(X_test_scaled):\n",
    "            raise ValueError(\"O 'sequence_length' não pode ser maior que o número de amostras em 'X_test_scaled'.\")\n",
    "        \n",
    "        # Calcula o comprimento dos intervalos de treino e teste, assumindo que 'X_train' e 'y_train' têm o mesmo comprimento, tal como 'X_test' e\n",
    "        # 'y_test'.\n",
    "        train_interval_length = len(X_train_scaled) - sequence_length\n",
    "        test_interval_length = len(X_test_scaled) - sequence_length\n",
    "        \n",
    "        # Inicializa listas para armazenar as sequências temporais dos dados de treino e teste.\n",
    "        X_train_sequences = []\n",
    "        X_test_sequences = []\n",
    "        y_train_sequences = []\n",
    "        y_test_sequences = []\n",
    "    \n",
    "        # Cria sequências temporais para os dados de treino\n",
    "        for i in range(train_interval_length):\n",
    "            # Cria uma sequência temporal de 'sequence_length' dias para as features de treino.\n",
    "            X_train_sequence = X_train_scaled[i: (i + sequence_length)]\n",
    "            # O alvo será o valor no dia seguinte após a sequência temporal.\n",
    "            y_train_sequence = y_train_scaled[i + sequence_length]\n",
    "            # Adiciona as sequências temporais às listas correspondentes.\n",
    "            X_train_sequences.append(X_train_sequence)\n",
    "            y_train_sequences.append(y_train_sequence)\n",
    "\n",
    "        # Cria sequências temporais para os dados de teste\n",
    "        for j in range(test_interval_length):\n",
    "            # Cria uma sequência temporal de 'sequence_length' dias para as features de teste.\n",
    "            X_test_sequence = X_test_scaled[j: (j + sequence_length)]\n",
    "            # O alvo será o valor no dia seguinte após a sequência temporal.\n",
    "            y_test_sequence = y_test_scaled[j + sequence_length]\n",
    "            # Adiciona as sequências temporais às listas correspondentes.\n",
    "            X_test_sequences.append(X_test_sequence)\n",
    "            y_test_sequences.append(y_test_sequence)\n",
    "            \n",
    "        # Converte as listas em arrays.\n",
    "        X_train_scaled_sequences = np.array([np.array(arr) for arr in X_train_sequences])\n",
    "        X_test_scaled_sequences = np.array([np.array(arr) for arr in X_test_sequences])\n",
    "        y_train_scaled_sequences = np.array(y_train_sequences)\n",
    "        y_test_scaled_sequences = np.array(y_test_sequences)\n",
    "        \n",
    "        return X_train_scaled_sequences, X_test_scaled_sequences, y_train_scaled_sequences, y_test_scaled_sequences\n",
    "    \n",
    "    def prepare_data_for_lstm(self, test_initial_day: datetime.date, test_final_day: datetime.date, lstm_time_sequences_length: int) -> tuple[np.ndarray,np.ndarray,np.ndarray,np.ndarray]:\n",
    "        '''\n",
    "            Description:\n",
    "                Prepara os dados para serem usados em uma LSTM. O processo envolve dividir os dados em conjuntos de treino e teste,\n",
    "                normalizar os dados e criar sequências temporais para a LSTM.\n",
    "                \n",
    "                Observação: A rede neural será treinada com todos os dados antes da data \"test_initial_day\" e fará predições para \n",
    "                            todas as datas entre test_initial_day e test_final_day (inclusos).\n",
    "\n",
    "            Args:\n",
    "                test_initial_day (datetime.date): Data que define o início do período de teste.\n",
    "                test_final_day (datetime.date): Data que define o final do período de teste.\n",
    "                lstm_time_sequences_length (int): O comprimento das sequências temporais usadas para treinar a LSTM.\n",
    "\n",
    "            Return:\n",
    "                tuple: Retorna quatro elementos - X_train_scaled_sequences, X_test_scaled_sequences, \n",
    "                    y_train_scaled_sequences, y_test_scaled_sequences (sequências temporais normalizadas para treino e teste).\n",
    "        '''\n",
    "\n",
    "        \n",
    "        # Divide os dados em conjuntos de treino e teste.\n",
    "        X_train, X_test, y_train, y_test = self.train_test_split(test_initial_day, test_final_day)\n",
    "        \n",
    "        # Normaliza os dados.\n",
    "        X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = self.scale_data(X_train, X_test, y_train, y_test)\n",
    "        \n",
    "        # Cria sequências temporais para a LSTM.\n",
    "        X_train_scaled_sequences, X_test_scaled_sequences, y_train_scaled_sequences, y_test_scaled_sequences = self.create_time_sequences_for_lstm(X_train_scaled, X_test_scaled,\n",
    "                                                                                                                   y_train_scaled, y_test_scaled,\n",
    "                                                                                                                   lstm_time_sequences_length)\n",
    "        \n",
    "        return X_train_scaled_sequences, X_test_scaled_sequences, y_train_scaled_sequences, y_test_scaled_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Definindo a classe Tickers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tickers:\n",
    "    '''\n",
    "        Description:\n",
    "            A classe \"Tickers\" serve como um contêiner para armazenar e padronizar múltiplos objetos \"Ticker\", garantindo que todos os\n",
    "            dados extraídos dos tickers tenham o mesmo intervalo de datas de negociação. Isso é útil para análises financeiras que\n",
    "            exigem comparabilidade entre diferentes ativos ao longo de um período comum. A classe também valida os tickers e armazena\n",
    "            apenas aqueles que possuem dados válidos.\n",
    "    '''\n",
    "    \n",
    "    def __get_tickers_data__(self) -> None:\n",
    "        '''\n",
    "            Description:\n",
    "                Itera sobre a lista de símbolos de tickers (tickers_list), cria um objeto Ticker para cada símbolo e salva os dados \n",
    "                no atributo \"data\" caso o ticker seja válido.\n",
    "            \n",
    "            Args:\n",
    "                Nenhum argumento é passado diretamente, pois a função utiliza os atributos do objeto.\n",
    "            \n",
    "            Return:\n",
    "                None: A função não retorna nada, mas preenche o array \"data\" com os objetos \"Ticker\" válidos.\n",
    "        '''\n",
    "        \n",
    "        # Itera sobre cada um dos símbolos presentes em \"tickers_list\".\n",
    "        for i, symbol in enumerate(self.symbols_list):\n",
    "            # Cria um objeto \"Ticker\" para o símbolo atual.\n",
    "            ticker = Ticker(symbol, self.data_extraction_initial_date, self.data_extraction_final_date, setup['features_time_period'])\n",
    "            # Se o ticker for válido, salva o objeto \"Ticker\" no array \"data\".\n",
    "            if(ticker.is_valid): self.symbols[i] = ticker\n",
    "    \n",
    "    def __init__(self, symbols_list: list, data_extraction_initial_date: datetime.date,\n",
    "                 data_extraction_final_date: datetime.date) -> None:\n",
    "        '''\n",
    "            Description:\n",
    "                Inicializa a classe \"Tickers\", criando uma lista de objetos \"Ticker\" com base na lista de símbolos e nas datas de extração\n",
    "                fornecidas. A classe também armazena os objetos \"Ticker\" válidos no atributo \"data\".\n",
    "            \n",
    "            Args:\n",
    "                symbols_list (list): A lista de símbolos (tickers) para os quais os dados serão extraídos.\n",
    "                data_extraction_initial_date (datetime.date): A data inicial para a extração dos dados.\n",
    "                data_extraction_final_date (datetime.date): A data final para a extração dos dados.\n",
    "            \n",
    "            Return:\n",
    "                None: A função não retorna nada, mas inicializa a instância com os tickers válidos e seus dados.\n",
    "        '''\n",
    "        \n",
    "        # Cria um array que guardará os objetos \"Ticker\" válidos.\n",
    "        self.symbols =  np.empty(len(symbols_list), dtype=object)\n",
    "\n",
    "        # Define a lista de símbolos de tickers.\n",
    "        self.symbols_list = symbols_list\n",
    "        \n",
    "        # Define a data inicial para a extração dos dados.\n",
    "        self.data_extraction_initial_date = data_extraction_initial_date\n",
    "        \n",
    "        # Define a data final para a extração dos dados.\n",
    "        self.data_extraction_final_date = data_extraction_final_date\n",
    "        \n",
    "        # Preenche o array \"tickers\" com os tickers válidos.\n",
    "        self.__get_tickers_data__()\n",
    "        \n",
    "        # Remove os valores nulos (None) do array \"data\".\n",
    "        self.symbols = self.symbols[self.tickers != None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Definindo os parâmetros iniciais**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Obtendo a lista de tickers do S&P500*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MMM',\n",
       " 'AOS',\n",
       " 'ABT',\n",
       " 'ABBV',\n",
       " 'ACN',\n",
       " 'ADBE',\n",
       " 'AMD',\n",
       " 'AES',\n",
       " 'AFL',\n",
       " 'A',\n",
       " 'APD',\n",
       " 'ABNB',\n",
       " 'AKAM',\n",
       " 'ALB',\n",
       " 'ARE',\n",
       " 'ALGN',\n",
       " 'ALLE',\n",
       " 'LNT',\n",
       " 'ALL',\n",
       " 'GOOGL',\n",
       " 'GOOG',\n",
       " 'MO',\n",
       " 'AMZN',\n",
       " 'AMCR',\n",
       " 'AMTM',\n",
       " 'AEE',\n",
       " 'AEP',\n",
       " 'AXP',\n",
       " 'AIG',\n",
       " 'AMT',\n",
       " 'AWK',\n",
       " 'AMP',\n",
       " 'AME',\n",
       " 'AMGN',\n",
       " 'APH',\n",
       " 'ADI',\n",
       " 'ANSS',\n",
       " 'AON',\n",
       " 'APA',\n",
       " 'AAPL',\n",
       " 'AMAT',\n",
       " 'APTV',\n",
       " 'ACGL',\n",
       " 'ADM',\n",
       " 'ANET',\n",
       " 'AJG',\n",
       " 'AIZ',\n",
       " 'T',\n",
       " 'ATO',\n",
       " 'ADSK',\n",
       " 'ADP',\n",
       " 'AZO',\n",
       " 'AVB',\n",
       " 'AVY',\n",
       " 'AXON',\n",
       " 'BKR',\n",
       " 'BALL',\n",
       " 'BAC',\n",
       " 'BAX',\n",
       " 'BDX',\n",
       " 'BRK.B',\n",
       " 'BBY',\n",
       " 'TECH',\n",
       " 'BIIB',\n",
       " 'BLK',\n",
       " 'BX',\n",
       " 'BK',\n",
       " 'BA',\n",
       " 'BKNG',\n",
       " 'BWA',\n",
       " 'BSX',\n",
       " 'BMY',\n",
       " 'AVGO',\n",
       " 'BR',\n",
       " 'BRO',\n",
       " 'BF.B',\n",
       " 'BLDR',\n",
       " 'BG',\n",
       " 'BXP',\n",
       " 'CHRW',\n",
       " 'CDNS',\n",
       " 'CZR',\n",
       " 'CPT',\n",
       " 'CPB',\n",
       " 'COF',\n",
       " 'CAH',\n",
       " 'KMX',\n",
       " 'CCL',\n",
       " 'CARR',\n",
       " 'CTLT',\n",
       " 'CAT',\n",
       " 'CBOE',\n",
       " 'CBRE',\n",
       " 'CDW',\n",
       " 'CE',\n",
       " 'COR',\n",
       " 'CNC',\n",
       " 'CNP',\n",
       " 'CF',\n",
       " 'CRL',\n",
       " 'SCHW',\n",
       " 'CHTR',\n",
       " 'CVX',\n",
       " 'CMG',\n",
       " 'CB',\n",
       " 'CHD',\n",
       " 'CI',\n",
       " 'CINF',\n",
       " 'CTAS',\n",
       " 'CSCO',\n",
       " 'C',\n",
       " 'CFG',\n",
       " 'CLX',\n",
       " 'CME',\n",
       " 'CMS',\n",
       " 'KO',\n",
       " 'CTSH',\n",
       " 'CL',\n",
       " 'CMCSA',\n",
       " 'CAG',\n",
       " 'COP',\n",
       " 'ED',\n",
       " 'STZ',\n",
       " 'CEG',\n",
       " 'COO',\n",
       " 'CPRT',\n",
       " 'GLW',\n",
       " 'CPAY',\n",
       " 'CTVA',\n",
       " 'CSGP',\n",
       " 'COST',\n",
       " 'CTRA',\n",
       " 'CRWD',\n",
       " 'CCI',\n",
       " 'CSX',\n",
       " 'CMI',\n",
       " 'CVS',\n",
       " 'DHR',\n",
       " 'DRI',\n",
       " 'DVA',\n",
       " 'DAY',\n",
       " 'DECK',\n",
       " 'DE',\n",
       " 'DELL',\n",
       " 'DAL',\n",
       " 'DVN',\n",
       " 'DXCM',\n",
       " 'FANG',\n",
       " 'DLR',\n",
       " 'DFS',\n",
       " 'DG',\n",
       " 'DLTR',\n",
       " 'D',\n",
       " 'DPZ',\n",
       " 'DOV',\n",
       " 'DOW',\n",
       " 'DHI',\n",
       " 'DTE',\n",
       " 'DUK',\n",
       " 'DD',\n",
       " 'EMN',\n",
       " 'ETN',\n",
       " 'EBAY',\n",
       " 'ECL',\n",
       " 'EIX',\n",
       " 'EW',\n",
       " 'EA',\n",
       " 'ELV',\n",
       " 'EMR',\n",
       " 'ENPH',\n",
       " 'ETR',\n",
       " 'EOG',\n",
       " 'EPAM',\n",
       " 'EQT',\n",
       " 'EFX',\n",
       " 'EQIX',\n",
       " 'EQR',\n",
       " 'ERIE',\n",
       " 'ESS',\n",
       " 'EL',\n",
       " 'EG',\n",
       " 'EVRG',\n",
       " 'ES',\n",
       " 'EXC',\n",
       " 'EXPE',\n",
       " 'EXPD',\n",
       " 'EXR',\n",
       " 'XOM',\n",
       " 'FFIV',\n",
       " 'FDS',\n",
       " 'FICO',\n",
       " 'FAST',\n",
       " 'FRT',\n",
       " 'FDX',\n",
       " 'FIS',\n",
       " 'FITB',\n",
       " 'FSLR',\n",
       " 'FE',\n",
       " 'FI',\n",
       " 'FMC',\n",
       " 'F',\n",
       " 'FTNT',\n",
       " 'FTV',\n",
       " 'FOXA',\n",
       " 'FOX',\n",
       " 'BEN',\n",
       " 'FCX',\n",
       " 'GRMN',\n",
       " 'IT',\n",
       " 'GE',\n",
       " 'GEHC',\n",
       " 'GEV',\n",
       " 'GEN',\n",
       " 'GNRC',\n",
       " 'GD',\n",
       " 'GIS',\n",
       " 'GM',\n",
       " 'GPC',\n",
       " 'GILD',\n",
       " 'GPN',\n",
       " 'GL',\n",
       " 'GDDY',\n",
       " 'GS',\n",
       " 'HAL',\n",
       " 'HIG',\n",
       " 'HAS',\n",
       " 'HCA',\n",
       " 'DOC',\n",
       " 'HSIC',\n",
       " 'HSY',\n",
       " 'HES',\n",
       " 'HPE',\n",
       " 'HLT',\n",
       " 'HOLX',\n",
       " 'HD',\n",
       " 'HON',\n",
       " 'HRL',\n",
       " 'HST',\n",
       " 'HWM',\n",
       " 'HPQ',\n",
       " 'HUBB',\n",
       " 'HUM',\n",
       " 'HBAN',\n",
       " 'HII',\n",
       " 'IBM',\n",
       " 'IEX',\n",
       " 'IDXX',\n",
       " 'ITW',\n",
       " 'INCY',\n",
       " 'IR',\n",
       " 'PODD',\n",
       " 'INTC',\n",
       " 'ICE',\n",
       " 'IFF',\n",
       " 'IP',\n",
       " 'IPG',\n",
       " 'INTU',\n",
       " 'ISRG',\n",
       " 'IVZ',\n",
       " 'INVH',\n",
       " 'IQV',\n",
       " 'IRM',\n",
       " 'JBHT',\n",
       " 'JBL',\n",
       " 'JKHY',\n",
       " 'J',\n",
       " 'JNJ',\n",
       " 'JCI',\n",
       " 'JPM',\n",
       " 'JNPR',\n",
       " 'K',\n",
       " 'KVUE',\n",
       " 'KDP',\n",
       " 'KEY',\n",
       " 'KEYS',\n",
       " 'KMB',\n",
       " 'KIM',\n",
       " 'KMI',\n",
       " 'KKR',\n",
       " 'KLAC',\n",
       " 'KHC',\n",
       " 'KR',\n",
       " 'LHX',\n",
       " 'LH',\n",
       " 'LRCX',\n",
       " 'LW',\n",
       " 'LVS',\n",
       " 'LDOS',\n",
       " 'LEN',\n",
       " 'LLY',\n",
       " 'LIN',\n",
       " 'LYV',\n",
       " 'LKQ',\n",
       " 'LMT',\n",
       " 'L',\n",
       " 'LOW',\n",
       " 'LULU',\n",
       " 'LYB',\n",
       " 'MTB',\n",
       " 'MRO',\n",
       " 'MPC',\n",
       " 'MKTX',\n",
       " 'MAR',\n",
       " 'MMC',\n",
       " 'MLM',\n",
       " 'MAS',\n",
       " 'MA',\n",
       " 'MTCH',\n",
       " 'MKC',\n",
       " 'MCD',\n",
       " 'MCK',\n",
       " 'MDT',\n",
       " 'MRK',\n",
       " 'META',\n",
       " 'MET',\n",
       " 'MTD',\n",
       " 'MGM',\n",
       " 'MCHP',\n",
       " 'MU',\n",
       " 'MSFT',\n",
       " 'MAA',\n",
       " 'MRNA',\n",
       " 'MHK',\n",
       " 'MOH',\n",
       " 'TAP',\n",
       " 'MDLZ',\n",
       " 'MPWR',\n",
       " 'MNST',\n",
       " 'MCO',\n",
       " 'MS',\n",
       " 'MOS',\n",
       " 'MSI',\n",
       " 'MSCI',\n",
       " 'NDAQ',\n",
       " 'NTAP',\n",
       " 'NFLX',\n",
       " 'NEM',\n",
       " 'NWSA',\n",
       " 'NWS',\n",
       " 'NEE',\n",
       " 'NKE',\n",
       " 'NI',\n",
       " 'NDSN',\n",
       " 'NSC',\n",
       " 'NTRS',\n",
       " 'NOC',\n",
       " 'NCLH',\n",
       " 'NRG',\n",
       " 'NUE',\n",
       " 'NVDA',\n",
       " 'NVR',\n",
       " 'NXPI',\n",
       " 'ORLY',\n",
       " 'OXY',\n",
       " 'ODFL',\n",
       " 'OMC',\n",
       " 'ON',\n",
       " 'OKE',\n",
       " 'ORCL',\n",
       " 'OTIS',\n",
       " 'PCAR',\n",
       " 'PKG',\n",
       " 'PLTR',\n",
       " 'PANW',\n",
       " 'PARA',\n",
       " 'PH',\n",
       " 'PAYX',\n",
       " 'PAYC',\n",
       " 'PYPL',\n",
       " 'PNR',\n",
       " 'PEP',\n",
       " 'PFE',\n",
       " 'PCG',\n",
       " 'PM',\n",
       " 'PSX',\n",
       " 'PNW',\n",
       " 'PNC',\n",
       " 'POOL',\n",
       " 'PPG',\n",
       " 'PPL',\n",
       " 'PFG',\n",
       " 'PG',\n",
       " 'PGR',\n",
       " 'PLD',\n",
       " 'PRU',\n",
       " 'PEG',\n",
       " 'PTC',\n",
       " 'PSA',\n",
       " 'PHM',\n",
       " 'QRVO',\n",
       " 'PWR',\n",
       " 'QCOM',\n",
       " 'DGX',\n",
       " 'RL',\n",
       " 'RJF',\n",
       " 'RTX',\n",
       " 'O',\n",
       " 'REG',\n",
       " 'REGN',\n",
       " 'RF',\n",
       " 'RSG',\n",
       " 'RMD',\n",
       " 'RVTY',\n",
       " 'ROK',\n",
       " 'ROL',\n",
       " 'ROP',\n",
       " 'ROST',\n",
       " 'RCL',\n",
       " 'SPGI',\n",
       " 'CRM',\n",
       " 'SBAC',\n",
       " 'SLB',\n",
       " 'STX',\n",
       " 'SRE',\n",
       " 'NOW',\n",
       " 'SHW',\n",
       " 'SPG',\n",
       " 'SWKS',\n",
       " 'SJM',\n",
       " 'SW',\n",
       " 'SNA',\n",
       " 'SOLV',\n",
       " 'SO',\n",
       " 'LUV',\n",
       " 'SWK',\n",
       " 'SBUX',\n",
       " 'STT',\n",
       " 'STLD',\n",
       " 'STE',\n",
       " 'SYK',\n",
       " 'SMCI',\n",
       " 'SYF',\n",
       " 'SNPS',\n",
       " 'SYY',\n",
       " 'TMUS',\n",
       " 'TROW',\n",
       " 'TTWO',\n",
       " 'TPR',\n",
       " 'TRGP',\n",
       " 'TGT',\n",
       " 'TEL',\n",
       " 'TDY',\n",
       " 'TFX',\n",
       " 'TER',\n",
       " 'TSLA',\n",
       " 'TXN',\n",
       " 'TXT',\n",
       " 'TMO',\n",
       " 'TJX',\n",
       " 'TSCO',\n",
       " 'TT',\n",
       " 'TDG',\n",
       " 'TRV',\n",
       " 'TRMB',\n",
       " 'TFC',\n",
       " 'TYL',\n",
       " 'TSN',\n",
       " 'USB',\n",
       " 'UBER',\n",
       " 'UDR',\n",
       " 'ULTA',\n",
       " 'UNP',\n",
       " 'UAL',\n",
       " 'UPS',\n",
       " 'URI',\n",
       " 'UNH',\n",
       " 'UHS',\n",
       " 'VLO',\n",
       " 'VTR',\n",
       " 'VLTO',\n",
       " 'VRSN',\n",
       " 'VRSK',\n",
       " 'VZ',\n",
       " 'VRTX',\n",
       " 'VTRS',\n",
       " 'VICI',\n",
       " 'V',\n",
       " 'VST',\n",
       " 'VMC',\n",
       " 'WRB',\n",
       " 'GWW',\n",
       " 'WAB',\n",
       " 'WBA',\n",
       " 'WMT',\n",
       " 'DIS',\n",
       " 'WBD',\n",
       " 'WM',\n",
       " 'WAT',\n",
       " 'WEC',\n",
       " 'WFC',\n",
       " 'WELL',\n",
       " 'WST',\n",
       " 'WDC',\n",
       " 'WY',\n",
       " 'WMB',\n",
       " 'WTW',\n",
       " 'WYNN',\n",
       " 'XEL',\n",
       " 'XYL',\n",
       " 'YUM',\n",
       " 'ZBRA',\n",
       " 'ZBH',\n",
       " 'ZTS']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Essa célula será usada para se obter os tickets das companhias que fazem parte do S&P 500, com base em dados da wikipedia.\n",
    "'''\n",
    "\n",
    "# Salva em uma variável a url que contém a tabela com os tickets das companhias.\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "\n",
    "# Lê todas as tabelas presentes na url acima.\n",
    "sp500_table = pd.read_html(url)\n",
    "\n",
    "# Salva a coluna \"Symbol\" da primeira tabela em uma variável (tal coluna contém todos os tickets das companhias que fazem parte do S&P 500).\n",
    "sp500_tickets = sp500_table[0]['Symbol']\n",
    "\n",
    "# Transforma os tickets obtidos em uma lista.\n",
    "sp500_tickets = sp500_tickets.tolist()\n",
    "\n",
    "# Exibe a lista de tickets criada acima.\n",
    "sp500_tickets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Definindo a data inicial e a data final para a extração de dados dos tickers*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Essa célula será usada para definir o intervalo de tempo dos dados que serão coletados, especificando a data de início e a data de fim.\n",
    "'''\n",
    "\n",
    "# Define a data inicial cujos dados serão coletados (Primeiro dia de negociações do S&P500 em 2019).\n",
    "data_extraction_initial_date = datetime(2019,1,2).date() # Deve obrigatoriamente ser um dia de negociação.\n",
    "# Define a data final cujos dados serão coletados (Último dia de negociações do S&P500 em 2023).\n",
    "data_extraction_final_date = datetime(2023,12,30).date() # Deve obrigatoriamente ser um dia de negociação e deve também obrigatoriamente\n",
    "                                                         # suceder um dia de negociação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Definindo alguns parâmetros que serão importantes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Essa célula será usada para criar um dicionário chamado setup, que contém os parâmetros principais para a coleta de dados, \n",
    "    incluindo a lista de tickers das companhias do S&P 500 e o intervalo de tempo.\n",
    "'''\n",
    "\n",
    "# Cria um dicionário para guardar alguns parâmetros importantes para a coleta de dados.\n",
    "setup = {\n",
    "    #\n",
    "    \"symbols\": sp500_tickets,\n",
    "    #\n",
    "    \"data_extraction_initial_date\": data_extraction_initial_date,\n",
    "    #\n",
    "    \"data_extraction_final_date\": data_extraction_final_date,\n",
    "    #\n",
    "    \"features_time_period\": {\n",
    "        \"returns_time_period\": 1,\n",
    "        \"exponential_moving_average_time_period\": 14,\n",
    "        \"relative_strength_index_time_period\": 14,\n",
    "        \"average_true_range_time_period\": 14,\n",
    "        \"momemtum_time_period\": 14\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Testes**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
