{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Configurando as bibliotecas do projeto**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Instalação de bibliotecas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: Ta-Lib in /home/user/.local/lib/python3.10/site-packages (0.4.32)\n",
      "Requirement already satisfied: numpy in /home/user/.local/lib/python3.10/site-packages (from Ta-Lib) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "# Instala a biblioteca \"TA-Lib\" que será responsável por fornecer a implementação de alguns indicadores técnicos.\n",
    "!pip install Ta-Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tensorflow in /home/user/.local/lib/python3.10/site-packages (2.17.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (2.17.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: packaging in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (1.66.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (1.24.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (4.25.4)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (4.10.0)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (3.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/user/.local/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: optree in /home/user/.local/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: namex in /home/user/.local/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: rich in /home/user/.local/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (13.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user/.local/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/user/.local/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/user/.local/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/user/.local/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/user/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/user/.local/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/user/.local/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/user/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "# Instala a biblioteca \"tensorflow\" que será responsável por fornecer a implementação dos métodos necessários para a construção da LSTM.\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Importação de bibliotecas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Essa célula será usada para a importação de bibliotecas.\n",
    "'''\n",
    "\n",
    "# Importa a biblioteca que será utilizada para a obtenção dos dados financeiros.\n",
    "import yfinance as yf\n",
    "# Importa a biblioteca que será utilizada para a manipulação de DataFrames.\n",
    "import pandas as pd\n",
    "# Importa o módulo da biblioteca \"datetime\" que será utilizada para lidar com objetos do tipo \"datetime\".\n",
    "from datetime import datetime, timedelta\n",
    "# Importa o módulo da biblioteca \"typing\" que será utilizado para tipar parâmetros opcionais de funções.\n",
    "from typing import Optional\n",
    "# Importa a biblioteca que será utilizada para a manipulação de arrays e também para o uso de algumas funções matemáticas.\n",
    "import numpy as np\n",
    "# Importa a biblioteca que será utilizada para calcular algumas métricas de análise técnica.\n",
    "import talib\n",
    "# Importa o módulo da biblioteca \"sklearn\" que será utilizado para escalar as features dos DataFrames que serão usados no modelo LSTM.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Importa um dos módulos da biblioteca \"tensorflow\" que será utilizado para criar o modelo LSTM. \n",
    "from keras.models import Sequential\n",
    "# Importa um dos módulos da biblioteca \"tensorflow\" que será utilizado para construir as camadas que farão parte da arquitetura do modelo LSTM \n",
    "# a ser usado. \n",
    "from keras.layers import LSTM, Dense, Dropout, Input\n",
    "# Importa a biblioteca que será utilizada para criar gráficos interativos.\n",
    "import plotly.graph_objects as go\n",
    "# Importa a função \"mean_squared_error\" da biblioteca sklearn.metrics.\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Definindo a classe Ticker**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ticker:\n",
    "    '''\n",
    "        Description:\n",
    "            A classe \"Ticker\" representa um ativo financeiro identificado por um símbolo único (ticker). \n",
    "            Ela é responsável por baixar os dados históricos de preços e calcular vários indicadores técnicos, \n",
    "            como retornos aritméticos e logarítmicos, Bandas de Bollinger, RSI (Índice de Força Relativa), \n",
    "            ATR (Average True Range) e Momentum. O objetivo principal da classe é fornecer um conjunto padronizado de dados \n",
    "            e indicadores para análise de ativos financeiros. Além disso, valida se os dados extraídos estão de acordo com \n",
    "            o período solicitado e prepara os dados para uso posterior, como em modelos de aprendizado de máquina.\n",
    "    '''\n",
    "    \n",
    "    def __is_ticker_valid__(self) -> bool:\n",
    "        '''\n",
    "            Description:\n",
    "                Verifica se o ticker é considerado válido. Um ticker será considerado válido quando:\n",
    "                - O atributo `data` não for vazio.\n",
    "                - O índice inicial do atributo `data` corresponder à data de extração inicial (`data_extraction_initial_date`).\n",
    "                - O índice final do atributo `data` corresponder à data de extração final (`data_extraction_final_date` - 1 dia).\n",
    "            \n",
    "            Args:\n",
    "                Nenhum argumento é passado diretamente para esta função, pois ela usa os atributos do objeto \n",
    "                (`self.data`, `self.data_extraction_initial_date`, etc.).\n",
    "\n",
    "            Return:\n",
    "                bool: Retorna `True` se o ticker for considerado válido de acordo com as condições definidas, caso contrário retorna `False`.\n",
    "        '''\n",
    "        \n",
    "        # Verifica se o atributo data é vazio.\n",
    "        if(len(self.data) == 0): return False\n",
    "        \n",
    "        # Verifica se a data inicial do índice do DataFrame corresponde à data de extração inicial.\n",
    "        condition_2 = (self.data.index[0].date() == self.data_extraction_initial_date)\n",
    "        # Verifica se a data final do índice do DataFrame corresponde à data de extração final - 1 dia.\n",
    "        condition_3 = (self.data.index[len(self.data.index)-1].date() == self.data_extraction_final_date - timedelta(days=1))\n",
    "        \n",
    "        # Observação: Irá ocorrer problemas com as condições acima caso self.data_extraction_initial_date ou self.data_extraction_final_data \n",
    "        # não sejam dias de negociação. Visto que, caso isso ocorra, tais condições serão falsas e consequentemente o Ticker em questão \n",
    "        # não será considerado válido.\n",
    "        \n",
    "        # Retorna False se alguma das condições não for satisfeita.\n",
    "        if(not(condition_2) or not(condition_3)):\n",
    "            return False\n",
    "        \n",
    "        # Retorna True caso contrário (se todas as condições forem satisfeitas).\n",
    "        return True\n",
    "        \n",
    "        \n",
    "    def __get_ticker_data__(self) -> pd.DataFrame:\n",
    "        '''\n",
    "            Description:\n",
    "                Baixa os dados do ticker usando a biblioteca `yfinance` para o período de tempo definido pelos atributos \n",
    "                `data_extraction_initial_date` e `data_extraction_final_date`.\n",
    "                \n",
    "            Args:\n",
    "                Nenhum argumento é passado diretamente para esta função, pois ela utiliza os atributos do objeto \n",
    "                (`self.symbol`, `self.data_extraction_initial_date`, etc.).\n",
    "            \n",
    "            Return:\n",
    "                pd.DataFrame: Um DataFrame contendo os dados históricos do ticker para o período solicitado. \n",
    "                Retorna um DataFrame vazio se ocorrer algum erro.\n",
    "        '''\n",
    "        \n",
    "        try:\n",
    "            # Faz o download dos dados do ticker em questão.\n",
    "            return yf.download(self.symbol, \n",
    "                               start=self.data_extraction_initial_date, \n",
    "                               end=self.data_extraction_final_date)\n",
    "        except Exception as e:  \n",
    "            # Captura e imprime a exceção caso ocorra um erro ao baixar os dados.\n",
    "            print(f\"Erro ao baixar os dados para {self.symbol}: {e}\")\n",
    "            # Retorna um DataFrame vazio em caso de erro.\n",
    "            return pd.DataFrame()  \n",
    "        \n",
    "    def __get_arithmetic_returns__(self) -> pd.Series:\n",
    "        '''\n",
    "            Description:\n",
    "                Calcula os retornos aritméticos baseados nos preços ajustados de fechamento (Adj Close).\n",
    "                O retorno aritmético mede a variação percentual do preço de fechamento ajustado em relação ao período anterior.\n",
    "                \n",
    "            Args:\n",
    "                Nenhum argumento é passado diretamente, pois a função utiliza os atributos do objeto.\n",
    "            \n",
    "            Return:\n",
    "                pd.Series: Uma série com os retornos aritméticos para o período definido, divididos por 100 para normalizar os valores.\n",
    "        '''\n",
    "        \n",
    "        # Obtém os preços ajustados de fechamento.\n",
    "        daily_prices = self.data['Adj Close']\n",
    "\n",
    "        # Calcula os retornos aritméticos usando o método ROC da talib.\n",
    "        arithmetic_returns = talib.ROC(daily_prices, timeperiod=self.__features_time_period__['returns_time_period']) \n",
    "        \n",
    "        # Normaliza os retornos dividindo por 100 (ROC retorna valores em percentual).\n",
    "        return (arithmetic_returns/100)\n",
    "    \n",
    "    def __get_logarithmic_returns__(self) -> pd.Series:\n",
    "        '''\n",
    "            Description:\n",
    "                Calcula os retornos logarítmicos baseados nos retornos aritméticos. \n",
    "                O retorno logarítmico é uma medida que transforma os retornos aritméticos em uma forma que facilita a análise estatística e \n",
    "                agregação de múltiplos retornos.\n",
    "            \n",
    "            Args:\n",
    "                Nenhum argumento é passado diretamente, pois a função utiliza os atributos do objeto.\n",
    "            \n",
    "            Return:\n",
    "                pd.Series: Uma série com os retornos logarítmicos.\n",
    "        '''\n",
    "        \n",
    "        # Obtém os retornos aritméticos.\n",
    "        arithmetic_returns = self.__get_arithmetic_returns__()\n",
    "        \n",
    "        # Calcula os retornos logarítmicos aplicando a função log(1 + retorno aritmético).\n",
    "        logarithmic_returns = arithmetic_returns.apply(lambda x: np.log(1 + x))\n",
    "        \n",
    "        return logarithmic_returns\n",
    "    \n",
    "    def __get_bollinger_bands_with_exponential_moving_average__(self) -> pd.Series:\n",
    "        '''\n",
    "            Description:\n",
    "                Calcula as Bandas de Bollinger com base na média móvel exponencial dos preços ajustados de fechamento (Adj Close).\n",
    "                As Bandas de Bollinger são usadas para medir a volatilidade e identificar potenciais pontos de reversão de tendência.\n",
    "            \n",
    "            Args:\n",
    "                Nenhum argumento é passado diretamente, pois a função utiliza os atributos do objeto.\n",
    "            \n",
    "            Return:\n",
    "                Tuple[pd.Series, pd.Series, pd.Series]: Um tuple contendo três séries: a banda superior, a banda média (EMA) e a banda inferior.\n",
    "        '''\n",
    "        \n",
    "        # Obtém os preços ajustados de fechamento.\n",
    "        daily_prices = self.data['Adj Close']\n",
    "        \n",
    "        # Calcula as Bandas de Bollinger usando o talib.\n",
    "        upper_band, middle_band, lower_band = talib.BBANDS(daily_prices, \n",
    "                                                           timeperiod=self.__features_time_period__['exponential_moving_average_time_period'],\n",
    "                                                           nbdevup=2, nbdevdn=2, matype=1) # Tipo de média móvel: 1 é a média móvel exponencial.\n",
    "        \n",
    "        return upper_band, middle_band, lower_band\n",
    "        \n",
    "    def __get_relative_strength_index__(self) -> pd.Series:\n",
    "        '''\n",
    "            Description:\n",
    "                Calcula o Índice de Força Relativa (RSI) com base nos preços ajustados de fechamento (Adj Close).\n",
    "                O RSI é um indicador de momentum usado para identificar condições de sobrecompra ou sobrevenda de um ativo.\n",
    "            \n",
    "            Args:\n",
    "                Nenhum argumento é passado diretamente, pois a função utiliza os atributos do objeto.\n",
    "            \n",
    "            Return:\n",
    "                pd.Series: Uma série contendo os valores do RSI para o período definido.\n",
    "        '''\n",
    "        \n",
    "        # Obtém os preços ajustados de fechamento.\n",
    "        daily_prices = self.data['Adj Close']\n",
    "        \n",
    "        # Calcula o RSI usando o talib.\n",
    "        relative_strength_index = talib.RSI(daily_prices, timeperiod=self.__features_time_period__['relative_strength_index_time_period'])\n",
    "        \n",
    "        return relative_strength_index\n",
    "    \n",
    "    def __get_average_true_range__(self) -> pd.Series:\n",
    "        '''\n",
    "            Description:\n",
    "                Calcula o Average True Range (ATR) baseado nas séries de preços máximos, mínimos e de fechamento.\n",
    "                O ATR é um indicador de volatilidade que mede a variação média entre o preço máximo e o preço mínimo do período.\n",
    "            \n",
    "            Args:\n",
    "                Nenhum argumento é passado diretamente, pois a função utiliza os atributos do objeto.\n",
    "            \n",
    "            Return:\n",
    "                pd.Series: Uma série contendo os valores do ATR para o período definido.\n",
    "        '''\n",
    "        \n",
    "        # Obtém as séries de preços máximos, mínimos e de fechamento.\n",
    "        high_prices = self.data['High']\n",
    "        low_prices = self.data['Low']\n",
    "        close_prices = self.data['Close']\n",
    "        \n",
    "        # Calcula o ATR usando o talib.\n",
    "        average_true_range = talib.ATR(high_prices, low_prices, close_prices, timeperiod=self.__features_time_period__['average_true_range_time_period'])\n",
    "\n",
    "        return average_true_range\n",
    "    \n",
    "    def __get_momemtum__(self) -> pd.Series:\n",
    "        '''\n",
    "            Description:\n",
    "                Calcula o indicador de momentum baseado nos preços ajustados de fechamento (Adj Close).\n",
    "                O momentum mede a taxa de variação dos preços, indicando a velocidade e direção das mudanças de preços.\n",
    "            \n",
    "            Args:\n",
    "                Nenhum argumento é passado diretamente, pois a função utiliza os atributos do objeto.\n",
    "            \n",
    "            Return:\n",
    "                pd.Series: Uma série contendo os valores de momentum para o período definido.\n",
    "        '''\n",
    "        \n",
    "        # Obtém os preços ajustados de fechamento.\n",
    "        daily_prices = self.data['Adj Close']\n",
    "        \n",
    "        # Calcula o momentum usando o talib\n",
    "        momemtum = talib.MOM(daily_prices, timeperiod=self.__features_time_period__['momemtum_time_period'])\n",
    "\n",
    "        return momemtum\n",
    "        \n",
    "    \n",
    "    def __init__(self, symbol: str, data_extraction_initial_date: datetime.date , data_extraction_final_date: datetime.date,\n",
    "                 features_time_period: dict) -> None:\n",
    "        '''\n",
    "            Description:\n",
    "                Inicializa uma instância da classe \"Ticker\", definindo os parâmetros essenciais como o símbolo do ativo financeiro,\n",
    "                o período de extração de dados e os períodos de tempo utilizados para calcular indicadores financeiros. Durante a inicialização,\n",
    "                os dados do ticker são baixados e validados.\n",
    "\n",
    "            Args:\n",
    "                symbol (str): O símbolo do ativo financeiro (ticker) cujos dados históricos serão extraídos.\n",
    "                data_extraction_initial_date (datetime.date): A data inicial para a extração dos dados.\n",
    "                data_extraction_final_date (datetime.date): A data final para a extração dos dados.\n",
    "                features_time_period (dict): Um dicionário que contém os parâmetros de tempo para o cálculo dos indicadores financeiros, \n",
    "                                            como RSI, Bandas de Bollinger, etc.\n",
    "            \n",
    "            Return:\n",
    "                None: O construtor não retorna nada, mas prepara a instância para que os dados e indicadores possam ser utilizados posteriormente.\n",
    "        '''\n",
    "        \n",
    "        # Define o símbolo do ticker.\n",
    "        self.symbol = symbol\n",
    "        \n",
    "        # Define a data inicial para extração dos dados.\n",
    "        self.data_extraction_initial_date = data_extraction_initial_date\n",
    "        \n",
    "        # Define a data final para extração dos dados.\n",
    "        self.data_extraction_final_date = data_extraction_final_date\n",
    "        \n",
    "        # Define os períodos de tempo para calcular os indicadores financeiros.\n",
    "        self.__features_time_period__ = features_time_period\n",
    "        \n",
    "        # Baixa os dados do ticker.\n",
    "        self.data = self.__get_ticker_data__()\n",
    "        \n",
    "        # Verifica se o ticker é válido.\n",
    "        self.is_valid = self.__is_ticker_valid__()\n",
    "    \n",
    "    def __set_features__(self) -> None:\n",
    "        '''\n",
    "            Description:\n",
    "                Calcula e adiciona alguns indicadores financeiros como colunas ao DataFrame 'data' da instância. \n",
    "                Esses indicadores incluem retornos logarítmicos, Bandas de Bollinger com média móvel exponencial, RSI, ATR e Momentum.\n",
    "            \n",
    "            Args:\n",
    "                Nenhum argumento é passado diretamente, pois a função utiliza os atributos do objeto.\n",
    "            \n",
    "            Return:\n",
    "                None: A função não retorna nada, mas modifica o DataFrame 'data' da instância.\n",
    "        '''\n",
    "        \n",
    "        # Adiciona os retornos logarítmicos ao DataFrame.\n",
    "        self.data['Log returns'] = self.__get_logarithmic_returns__()\n",
    "        \n",
    "        # Adiciona as Bandas de Bollinger (banda superior, EMA, banda inferior) ao DataFrame.\n",
    "        self.data['B. upper bands'], self.data['EMA'], self.data['B. lower bands'] = self.__get_bollinger_bands_with_exponential_moving_average__()\n",
    "        \n",
    "        # Adiciona o Índice de Força Relativa (RSI) ao DataFrame.\n",
    "        self.data['RSI'] = self.__get_relative_strength_index__()\n",
    "        \n",
    "        # Adiciona o Average True Range (ATR) ao DataFrame.\n",
    "        self.data['ATR'] = self.__get_average_true_range__()\n",
    "        \n",
    "        # Adiciona o indicador de Momentum ao DataFrame.\n",
    "        self.data['MOM'] = self.__get_momemtum__()\n",
    "    \n",
    "    def __remove_some_features__(self) -> None:\n",
    "        '''\n",
    "            Description:\n",
    "                Remove algumas colunas desnecessárias do DataFrame, especificamente as colunas 'Open', 'High', 'Low', e 'Close'.\n",
    "            \n",
    "            Args:\n",
    "                Nenhum argumento é passado diretamente, pois a função utiliza os atributos do objeto.\n",
    "            \n",
    "            Return:\n",
    "                None: A função não retorna nada, mas modifica o DataFrame 'data' da instância.\n",
    "        '''\n",
    "        \n",
    "        # Remove as colunas 'Open', 'High', 'Low' e 'Close' do DataFrame.\n",
    "        self.data.drop(columns=['Open','High','Low','Close'], inplace=True)\n",
    "        \n",
    "    def adjust_data(self) -> None:\n",
    "        '''\n",
    "            Description:\n",
    "                Prepara os dados do ticker, calculando e adicionando os indicadores financeiros (features) e realizando\n",
    "                a limpeza dos dados, caso o ticker seja válido. Este método é útil para garantir que o DataFrame 'data'\n",
    "                contenha as informações necessárias para análises subsequentes.\n",
    "            \n",
    "            Args:\n",
    "                Nenhum argumento é passado diretamente, pois a função utiliza os atributos do objeto.\n",
    "            \n",
    "            Return:\n",
    "                None: A função não retorna nada, mas modifica o DataFrame 'data' da instância ao adicionar indicadores e\n",
    "                remover colunas e linhas desnecessárias.\n",
    "        '''\n",
    "        \n",
    "        # Se o ticker for considerado válido:\n",
    "        if self.is_valid:\n",
    "            # Calcula e adiciona as features (indicadores financeiros) ao DataFrame.\n",
    "            self.__set_features__()\n",
    "            \n",
    "            # Remove algumas colunas que não serão necessárias.\n",
    "            self.__remove_some_features__()\n",
    "            \n",
    "            # Remove todas as linhas que contenham valores nulos (NaN) no DataFrame.\n",
    "            self.data.dropna(inplace=True)\n",
    "            \n",
    "    def __train_test_split__(self, test_initial_day: datetime.date, test_final_day: datetime.date) -> tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]:\n",
    "        '''\n",
    "            Description:\n",
    "                Divide os dados em conjuntos de treino e teste com base nas datas fornecidas. As features (X) e o alvo (y) são separados\n",
    "                e divididos em dados de treino e teste.\n",
    "\n",
    "            Args:\n",
    "                test_initial_day (datetime.date): Data que define o início do período de teste.\n",
    "                test_final_day (datetime.date): Data que define o final do período de teste.\n",
    "\n",
    "            Return:\n",
    "                tuple: Retorna quatro elementos - X_train (features de treino), X_test (features de teste), y_train (alvo de treino) e y_test (alvo de teste).\n",
    "        '''\n",
    "        \n",
    "        # Separa as features (X) e o target (y).\n",
    "        X = self.data.drop(columns=['Adj Close'])\n",
    "        y = self.data['Adj Close']\n",
    "        \n",
    "        # Separa o conjunto de séries temporais das features em dados de treino e dados de teste.\n",
    "        X_train, X_test = X[X.index < test_initial_day], X[(X.index >= test_initial_day) & (X.index <= test_final_day)]\n",
    "        \n",
    "        # Separa a série temporal do target em dados de treino e dados de teste.\n",
    "        y_train, y_test = y[y.index < test_initial_day], y[(y.index >= test_initial_day) & (y.index <= test_final_day)]\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def __scale_data__(self, X_train: pd.DataFrame, X_test: pd.DataFrame, y_train: pd.Series, y_test: pd.Series) -> tuple[np.ndarray,np.ndarray,np.ndarray,np.ndarray]:\n",
    "        '''\n",
    "            Description:\n",
    "                Normaliza as features e o target tanto para os conjuntos de treino quanto de teste usando o MinMaxScaler. Além disso,\n",
    "                redimensiona o alvo (y) para uma matriz bidimensional antes da normalização.\n",
    "\n",
    "            Args:\n",
    "                X_train (pd.DataFrame): Conjunto de treino das features.\n",
    "                X_test (pd.DataFrame): Conjunto de teste das features.\n",
    "                y_train (pd.Series): Conjunto de treino do alvo.\n",
    "                y_test (pd.Series): Conjunto de teste do alvo.\n",
    "\n",
    "            Return:\n",
    "                tuple: Retorna quatro elementos - X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled.\n",
    "        '''\n",
    "        \n",
    "        # Cria uma instancia do MinMaxScaler para as features do ticker em questão.\n",
    "        scaler_features = MinMaxScaler()\n",
    "\n",
    "        # Ajusta a instância criada acima ao conjunto de treino das features do ticker em questão.\n",
    "        X_train_scaled = scaler_features.fit_transform(X_train)  \n",
    "\n",
    "        # Redimensiona y_train para que ele seja bidimensional (Necessário para o MinMaxScaler).\n",
    "        resized_y_train = y_train.values.reshape(-1, 1)  \n",
    "\n",
    "        # Cria uma instancia do MinMaxScaler para o target do ticker em questão.\n",
    "        scaler_target = MinMaxScaler()\n",
    "\n",
    "        # Ajusta a instância criada acima ao conjunto de treino do target do ticker em questão.\n",
    "        y_train_scaled = scaler_target.fit_transform(resized_y_train)  \n",
    "\n",
    "        # Normaliza o conjunto de teste das features do ticker em questão usando a instância que foi criada e ajustada aos dados de treino\n",
    "        # desse mesmo ticker.\n",
    "        X_test_scaled = scaler_features.transform(X_test)  \n",
    "\n",
    "        # Redimensiona y_test para que seja bidimensional (Necessário para o MinMaxScaler).\n",
    "        resized_y_test = y_test.values.reshape(-1, 1) \n",
    "\n",
    "        # Normaliza o conjunto de teste do target  do ticker em questão usando a instância que foi criada e ajustada aos dados de treino desse\n",
    "        # mesmo ticker.\n",
    "        y_test_scaled = scaler_target.transform(resized_y_test)\n",
    "        \n",
    "        return X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled\n",
    "    \n",
    "    def __create_time_sequences_for_lstm__(self, X_train_scaled: np.ndarray, X_test_scaled: np.ndarray, y_train_scaled: np.ndarray,\n",
    "                              y_test_scaled: np.ndarray, sequence_length: int) -> tuple[np.ndarray,np.ndarray,np.ndarray,np.ndarray]:\n",
    "        '''\n",
    "            Description:\n",
    "                Constrói sequências temporais a partir dos dados normalizados de treino e teste, criando janelas móveis\n",
    "                de tamanho 'sequence_length'. Essas sequências são necessárias para treinar uma LSTM.\n",
    "\n",
    "            Args:\n",
    "                X_train_scaled (np.ndarray): Conjunto de treino normalizado das features.\n",
    "                X_test_scaled (np.ndarray): Conjunto de teste normalizado das features.\n",
    "                y_train_scaled (np.ndarray): Conjunto de treino normalizado do alvo.\n",
    "                y_test_scaled (np.ndarray): Conjunto de teste normalizado do alvo.\n",
    "                sequence_length (int): O comprimento das sequências temporais usadas para treinar a LSTM.\n",
    "\n",
    "            Return:\n",
    "                tuple: Retorna quatro elementos - X_train_scaled_sequences, X_test_scaled_sequences, \n",
    "                    y_train_scaled_sequences, y_test_scaled_sequences (sequências temporais normalizadas para treino e teste).\n",
    "        '''\n",
    "    \n",
    "        # Verifica se o sequence_length é maior que o número de amostras disponíveis\n",
    "        if sequence_length > len(X_train_scaled):\n",
    "            raise ValueError(\"O 'sequence_length' não pode ser maior que o número de amostras em 'X_train_scaled'.\")\n",
    "        if sequence_length > len(X_test_scaled):\n",
    "            raise ValueError(\"O 'sequence_length' não pode ser maior que o número de amostras em 'X_test_scaled'.\")\n",
    "        \n",
    "        # Calcula o comprimento dos intervalos de treino e teste, assumindo que 'X_train' e 'y_train' têm o mesmo comprimento, tal como 'X_test' e\n",
    "        # 'y_test'.\n",
    "        train_interval_length = len(X_train_scaled) - sequence_length\n",
    "        test_interval_length = len(X_test_scaled) - sequence_length\n",
    "        \n",
    "        # Inicializa listas para armazenar as sequências temporais dos dados de treino e teste.\n",
    "        X_train_sequences = []\n",
    "        X_test_sequences = []\n",
    "        y_train_sequences = []\n",
    "        y_test_sequences = []\n",
    "    \n",
    "        # Cria sequências temporais para os dados de treino\n",
    "        for i in range(train_interval_length):\n",
    "            # Cria uma sequência temporal de 'sequence_length' dias para as features de treino.\n",
    "            X_train_sequence = X_train_scaled[i: (i + sequence_length)]\n",
    "            # O alvo será o valor no dia seguinte após a sequência temporal.\n",
    "            y_train_sequence = y_train_scaled[i + sequence_length]\n",
    "            # Adiciona as sequências temporais às listas correspondentes.\n",
    "            X_train_sequences.append(X_train_sequence)\n",
    "            y_train_sequences.append(y_train_sequence)\n",
    "\n",
    "        # Cria sequências temporais para os dados de teste\n",
    "        for j in range(test_interval_length):\n",
    "            # Cria uma sequência temporal de 'sequence_length' dias para as features de teste.\n",
    "            X_test_sequence = X_test_scaled[j: (j + sequence_length)]\n",
    "            # O alvo será o valor no dia seguinte após a sequência temporal.\n",
    "            y_test_sequence = y_test_scaled[j + sequence_length]\n",
    "            # Adiciona as sequências temporais às listas correspondentes.\n",
    "            X_test_sequences.append(X_test_sequence)\n",
    "            y_test_sequences.append(y_test_sequence)\n",
    "            \n",
    "        # Converte as listas em arrays.\n",
    "        X_train_scaled_sequences = np.array([np.array(arr) for arr in X_train_sequences])\n",
    "        X_test_scaled_sequences = np.array([np.array(arr) for arr in X_test_sequences])\n",
    "        y_train_scaled_sequences = np.array(y_train_sequences)\n",
    "        y_test_scaled_sequences = np.array(y_test_sequences)\n",
    "        \n",
    "        return X_train_scaled_sequences, X_test_scaled_sequences, y_train_scaled_sequences, y_test_scaled_sequences\n",
    "    \n",
    "    def prepare_data_for_lstm(self, test_initial_day: datetime.date, test_final_day: datetime.date, lstm_time_sequences_length: int) -> tuple[np.ndarray,np.ndarray,np.ndarray,np.ndarray]:\n",
    "        '''\n",
    "            Description:\n",
    "                Prepara os dados para serem usados em uma LSTM. O processo envolve dividir os dados em conjuntos de treino e teste,\n",
    "                normalizar os dados e criar sequências temporais para a LSTM.\n",
    "                \n",
    "                Observação: A rede neural será treinada com todos os dados antes da data \"test_initial_day\" e fará predições para \n",
    "                            todas as datas entre test_initial_day e test_final_day (inclusos).\n",
    "\n",
    "            Args:\n",
    "                test_initial_day (datetime.date): Data que define o início do período de teste.\n",
    "                test_final_day (datetime.date): Data que define o final do período de teste.\n",
    "                lstm_time_sequences_length (int): O comprimento das sequências temporais usadas para treinar a LSTM.\n",
    "\n",
    "            Return:\n",
    "                tuple: Retorna quatro elementos - X_train_scaled_sequences, X_test_scaled_sequences, \n",
    "                    y_train_scaled_sequences, y_test_scaled_sequences (sequências temporais normalizadas para treino e teste).\n",
    "        '''\n",
    "\n",
    "        \n",
    "        # Divide os dados em conjuntos de treino e teste.\n",
    "        X_train, X_test, y_train, y_test = self.__train_test_split__(test_initial_day, test_final_day)\n",
    "        \n",
    "        # Normaliza os dados.\n",
    "        X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = self.__scale_data__(X_train, X_test, y_train, y_test)\n",
    "        \n",
    "        # Cria sequências temporais para a LSTM.\n",
    "        X_train_scaled_sequences, X_test_scaled_sequences, y_train_scaled_sequences, y_test_scaled_sequences = self.__create_time_sequences_for_lstm__(X_train_scaled, X_test_scaled,\n",
    "                                                                                                                   y_train_scaled, y_test_scaled,\n",
    "                                                                                                                   lstm_time_sequences_length)\n",
    "        \n",
    "        return X_train_scaled_sequences, X_test_scaled_sequences, y_train_scaled_sequences, y_test_scaled_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Definindo a classe Tickers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tickers:\n",
    "    '''\n",
    "        Description:\n",
    "            A classe \"Tickers\" serve como um contêiner para armazenar e padronizar múltiplos objetos \"Ticker\", garantindo que todos os\n",
    "            dados extraídos dos tickers tenham o mesmo intervalo de datas de negociação. Isso é útil para análises financeiras que\n",
    "            exigem comparabilidade entre diferentes ativos ao longo de um período comum. A classe também valida os tickers e armazena\n",
    "            apenas aqueles que possuem dados válidos.\n",
    "    '''\n",
    "    \n",
    "    def __get_tickers_data__(self) -> None:\n",
    "        '''\n",
    "            Description:\n",
    "                Itera sobre a lista de símbolos de tickers (tickers_list), cria um objeto Ticker para cada símbolo e salva os dados \n",
    "                no atributo \"data\" caso o ticker seja válido.\n",
    "            \n",
    "            Args:\n",
    "                Nenhum argumento é passado diretamente, pois a função utiliza os atributos do objeto.\n",
    "            \n",
    "            Return:\n",
    "                None: A função não retorna nada, mas preenche o array \"data\" com os objetos \"Ticker\" válidos.\n",
    "        '''\n",
    "        \n",
    "        # Itera sobre cada um dos símbolos presentes em \"tickers_list\".\n",
    "        for i, symbol in enumerate(self.symbols_list):\n",
    "            # Cria um objeto \"Ticker\" para o símbolo atual.\n",
    "            ticker = Ticker(symbol, self.data_extraction_initial_date, self.data_extraction_final_date, setup['features_time_period'])\n",
    "            # Se o ticker for válido, salva o objeto \"Ticker\" no array \"data\".\n",
    "            if(ticker.is_valid): self.symbols[i] = ticker\n",
    "    \n",
    "    def __init__(self, symbols_list: list, data_extraction_initial_date: datetime.date,\n",
    "                 data_extraction_final_date: datetime.date) -> None:\n",
    "        '''\n",
    "            Description:\n",
    "                Inicializa a classe \"Tickers\", criando uma lista de objetos \"Ticker\" com base na lista de símbolos e nas datas de extração\n",
    "                fornecidas. A classe também armazena os objetos \"Ticker\" válidos no atributo \"data\".\n",
    "            \n",
    "            Args:\n",
    "                symbols_list (list): A lista de símbolos (tickers) para os quais os dados serão extraídos.\n",
    "                data_extraction_initial_date (datetime.date): A data inicial para a extração dos dados.\n",
    "                data_extraction_final_date (datetime.date): A data final para a extração dos dados.\n",
    "            \n",
    "            Return:\n",
    "                None: A função não retorna nada, mas inicializa a instância com os tickers válidos e seus dados.\n",
    "        '''\n",
    "        \n",
    "        # Cria um array que guardará os objetos \"Ticker\" válidos.\n",
    "        self.symbols =  np.empty(len(symbols_list), dtype=object)\n",
    "\n",
    "        # Define a lista de símbolos de tickers.\n",
    "        self.symbols_list = symbols_list\n",
    "        \n",
    "        # Define a data inicial para a extração dos dados.\n",
    "        self.data_extraction_initial_date = data_extraction_initial_date\n",
    "        \n",
    "        # Define a data final para a extração dos dados.\n",
    "        self.data_extraction_final_date = data_extraction_final_date\n",
    "        \n",
    "        # Preenche o array \"tickers\" com os tickers válidos.\n",
    "        self.__get_tickers_data__()\n",
    "        \n",
    "        # Remove os valores nulos (None) do array \"data\".\n",
    "        self.symbols = self.symbols[self.tickers != None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Definindo os parâmetros iniciais**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Obtendo a lista de tickers do S&P500*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MMM',\n",
       " 'AOS',\n",
       " 'ABT',\n",
       " 'ABBV',\n",
       " 'ACN',\n",
       " 'ADBE',\n",
       " 'AMD',\n",
       " 'AES',\n",
       " 'AFL',\n",
       " 'A',\n",
       " 'APD',\n",
       " 'ABNB',\n",
       " 'AKAM',\n",
       " 'ALB',\n",
       " 'ARE',\n",
       " 'ALGN',\n",
       " 'ALLE',\n",
       " 'LNT',\n",
       " 'ALL',\n",
       " 'GOOGL',\n",
       " 'GOOG',\n",
       " 'MO',\n",
       " 'AMZN',\n",
       " 'AMCR',\n",
       " 'AMTM',\n",
       " 'AEE',\n",
       " 'AEP',\n",
       " 'AXP',\n",
       " 'AIG',\n",
       " 'AMT',\n",
       " 'AWK',\n",
       " 'AMP',\n",
       " 'AME',\n",
       " 'AMGN',\n",
       " 'APH',\n",
       " 'ADI',\n",
       " 'ANSS',\n",
       " 'AON',\n",
       " 'APA',\n",
       " 'AAPL',\n",
       " 'AMAT',\n",
       " 'APTV',\n",
       " 'ACGL',\n",
       " 'ADM',\n",
       " 'ANET',\n",
       " 'AJG',\n",
       " 'AIZ',\n",
       " 'T',\n",
       " 'ATO',\n",
       " 'ADSK',\n",
       " 'ADP',\n",
       " 'AZO',\n",
       " 'AVB',\n",
       " 'AVY',\n",
       " 'AXON',\n",
       " 'BKR',\n",
       " 'BALL',\n",
       " 'BAC',\n",
       " 'BAX',\n",
       " 'BDX',\n",
       " 'BRK.B',\n",
       " 'BBY',\n",
       " 'TECH',\n",
       " 'BIIB',\n",
       " 'BLK',\n",
       " 'BX',\n",
       " 'BK',\n",
       " 'BA',\n",
       " 'BKNG',\n",
       " 'BWA',\n",
       " 'BSX',\n",
       " 'BMY',\n",
       " 'AVGO',\n",
       " 'BR',\n",
       " 'BRO',\n",
       " 'BF.B',\n",
       " 'BLDR',\n",
       " 'BG',\n",
       " 'BXP',\n",
       " 'CHRW',\n",
       " 'CDNS',\n",
       " 'CZR',\n",
       " 'CPT',\n",
       " 'CPB',\n",
       " 'COF',\n",
       " 'CAH',\n",
       " 'KMX',\n",
       " 'CCL',\n",
       " 'CARR',\n",
       " 'CTLT',\n",
       " 'CAT',\n",
       " 'CBOE',\n",
       " 'CBRE',\n",
       " 'CDW',\n",
       " 'CE',\n",
       " 'COR',\n",
       " 'CNC',\n",
       " 'CNP',\n",
       " 'CF',\n",
       " 'CRL',\n",
       " 'SCHW',\n",
       " 'CHTR',\n",
       " 'CVX',\n",
       " 'CMG',\n",
       " 'CB',\n",
       " 'CHD',\n",
       " 'CI',\n",
       " 'CINF',\n",
       " 'CTAS',\n",
       " 'CSCO',\n",
       " 'C',\n",
       " 'CFG',\n",
       " 'CLX',\n",
       " 'CME',\n",
       " 'CMS',\n",
       " 'KO',\n",
       " 'CTSH',\n",
       " 'CL',\n",
       " 'CMCSA',\n",
       " 'CAG',\n",
       " 'COP',\n",
       " 'ED',\n",
       " 'STZ',\n",
       " 'CEG',\n",
       " 'COO',\n",
       " 'CPRT',\n",
       " 'GLW',\n",
       " 'CPAY',\n",
       " 'CTVA',\n",
       " 'CSGP',\n",
       " 'COST',\n",
       " 'CTRA',\n",
       " 'CRWD',\n",
       " 'CCI',\n",
       " 'CSX',\n",
       " 'CMI',\n",
       " 'CVS',\n",
       " 'DHR',\n",
       " 'DRI',\n",
       " 'DVA',\n",
       " 'DAY',\n",
       " 'DECK',\n",
       " 'DE',\n",
       " 'DELL',\n",
       " 'DAL',\n",
       " 'DVN',\n",
       " 'DXCM',\n",
       " 'FANG',\n",
       " 'DLR',\n",
       " 'DFS',\n",
       " 'DG',\n",
       " 'DLTR',\n",
       " 'D',\n",
       " 'DPZ',\n",
       " 'DOV',\n",
       " 'DOW',\n",
       " 'DHI',\n",
       " 'DTE',\n",
       " 'DUK',\n",
       " 'DD',\n",
       " 'EMN',\n",
       " 'ETN',\n",
       " 'EBAY',\n",
       " 'ECL',\n",
       " 'EIX',\n",
       " 'EW',\n",
       " 'EA',\n",
       " 'ELV',\n",
       " 'EMR',\n",
       " 'ENPH',\n",
       " 'ETR',\n",
       " 'EOG',\n",
       " 'EPAM',\n",
       " 'EQT',\n",
       " 'EFX',\n",
       " 'EQIX',\n",
       " 'EQR',\n",
       " 'ERIE',\n",
       " 'ESS',\n",
       " 'EL',\n",
       " 'EG',\n",
       " 'EVRG',\n",
       " 'ES',\n",
       " 'EXC',\n",
       " 'EXPE',\n",
       " 'EXPD',\n",
       " 'EXR',\n",
       " 'XOM',\n",
       " 'FFIV',\n",
       " 'FDS',\n",
       " 'FICO',\n",
       " 'FAST',\n",
       " 'FRT',\n",
       " 'FDX',\n",
       " 'FIS',\n",
       " 'FITB',\n",
       " 'FSLR',\n",
       " 'FE',\n",
       " 'FI',\n",
       " 'FMC',\n",
       " 'F',\n",
       " 'FTNT',\n",
       " 'FTV',\n",
       " 'FOXA',\n",
       " 'FOX',\n",
       " 'BEN',\n",
       " 'FCX',\n",
       " 'GRMN',\n",
       " 'IT',\n",
       " 'GE',\n",
       " 'GEHC',\n",
       " 'GEV',\n",
       " 'GEN',\n",
       " 'GNRC',\n",
       " 'GD',\n",
       " 'GIS',\n",
       " 'GM',\n",
       " 'GPC',\n",
       " 'GILD',\n",
       " 'GPN',\n",
       " 'GL',\n",
       " 'GDDY',\n",
       " 'GS',\n",
       " 'HAL',\n",
       " 'HIG',\n",
       " 'HAS',\n",
       " 'HCA',\n",
       " 'DOC',\n",
       " 'HSIC',\n",
       " 'HSY',\n",
       " 'HES',\n",
       " 'HPE',\n",
       " 'HLT',\n",
       " 'HOLX',\n",
       " 'HD',\n",
       " 'HON',\n",
       " 'HRL',\n",
       " 'HST',\n",
       " 'HWM',\n",
       " 'HPQ',\n",
       " 'HUBB',\n",
       " 'HUM',\n",
       " 'HBAN',\n",
       " 'HII',\n",
       " 'IBM',\n",
       " 'IEX',\n",
       " 'IDXX',\n",
       " 'ITW',\n",
       " 'INCY',\n",
       " 'IR',\n",
       " 'PODD',\n",
       " 'INTC',\n",
       " 'ICE',\n",
       " 'IFF',\n",
       " 'IP',\n",
       " 'IPG',\n",
       " 'INTU',\n",
       " 'ISRG',\n",
       " 'IVZ',\n",
       " 'INVH',\n",
       " 'IQV',\n",
       " 'IRM',\n",
       " 'JBHT',\n",
       " 'JBL',\n",
       " 'JKHY',\n",
       " 'J',\n",
       " 'JNJ',\n",
       " 'JCI',\n",
       " 'JPM',\n",
       " 'JNPR',\n",
       " 'K',\n",
       " 'KVUE',\n",
       " 'KDP',\n",
       " 'KEY',\n",
       " 'KEYS',\n",
       " 'KMB',\n",
       " 'KIM',\n",
       " 'KMI',\n",
       " 'KKR',\n",
       " 'KLAC',\n",
       " 'KHC',\n",
       " 'KR',\n",
       " 'LHX',\n",
       " 'LH',\n",
       " 'LRCX',\n",
       " 'LW',\n",
       " 'LVS',\n",
       " 'LDOS',\n",
       " 'LEN',\n",
       " 'LLY',\n",
       " 'LIN',\n",
       " 'LYV',\n",
       " 'LKQ',\n",
       " 'LMT',\n",
       " 'L',\n",
       " 'LOW',\n",
       " 'LULU',\n",
       " 'LYB',\n",
       " 'MTB',\n",
       " 'MRO',\n",
       " 'MPC',\n",
       " 'MKTX',\n",
       " 'MAR',\n",
       " 'MMC',\n",
       " 'MLM',\n",
       " 'MAS',\n",
       " 'MA',\n",
       " 'MTCH',\n",
       " 'MKC',\n",
       " 'MCD',\n",
       " 'MCK',\n",
       " 'MDT',\n",
       " 'MRK',\n",
       " 'META',\n",
       " 'MET',\n",
       " 'MTD',\n",
       " 'MGM',\n",
       " 'MCHP',\n",
       " 'MU',\n",
       " 'MSFT',\n",
       " 'MAA',\n",
       " 'MRNA',\n",
       " 'MHK',\n",
       " 'MOH',\n",
       " 'TAP',\n",
       " 'MDLZ',\n",
       " 'MPWR',\n",
       " 'MNST',\n",
       " 'MCO',\n",
       " 'MS',\n",
       " 'MOS',\n",
       " 'MSI',\n",
       " 'MSCI',\n",
       " 'NDAQ',\n",
       " 'NTAP',\n",
       " 'NFLX',\n",
       " 'NEM',\n",
       " 'NWSA',\n",
       " 'NWS',\n",
       " 'NEE',\n",
       " 'NKE',\n",
       " 'NI',\n",
       " 'NDSN',\n",
       " 'NSC',\n",
       " 'NTRS',\n",
       " 'NOC',\n",
       " 'NCLH',\n",
       " 'NRG',\n",
       " 'NUE',\n",
       " 'NVDA',\n",
       " 'NVR',\n",
       " 'NXPI',\n",
       " 'ORLY',\n",
       " 'OXY',\n",
       " 'ODFL',\n",
       " 'OMC',\n",
       " 'ON',\n",
       " 'OKE',\n",
       " 'ORCL',\n",
       " 'OTIS',\n",
       " 'PCAR',\n",
       " 'PKG',\n",
       " 'PLTR',\n",
       " 'PANW',\n",
       " 'PARA',\n",
       " 'PH',\n",
       " 'PAYX',\n",
       " 'PAYC',\n",
       " 'PYPL',\n",
       " 'PNR',\n",
       " 'PEP',\n",
       " 'PFE',\n",
       " 'PCG',\n",
       " 'PM',\n",
       " 'PSX',\n",
       " 'PNW',\n",
       " 'PNC',\n",
       " 'POOL',\n",
       " 'PPG',\n",
       " 'PPL',\n",
       " 'PFG',\n",
       " 'PG',\n",
       " 'PGR',\n",
       " 'PLD',\n",
       " 'PRU',\n",
       " 'PEG',\n",
       " 'PTC',\n",
       " 'PSA',\n",
       " 'PHM',\n",
       " 'QRVO',\n",
       " 'PWR',\n",
       " 'QCOM',\n",
       " 'DGX',\n",
       " 'RL',\n",
       " 'RJF',\n",
       " 'RTX',\n",
       " 'O',\n",
       " 'REG',\n",
       " 'REGN',\n",
       " 'RF',\n",
       " 'RSG',\n",
       " 'RMD',\n",
       " 'RVTY',\n",
       " 'ROK',\n",
       " 'ROL',\n",
       " 'ROP',\n",
       " 'ROST',\n",
       " 'RCL',\n",
       " 'SPGI',\n",
       " 'CRM',\n",
       " 'SBAC',\n",
       " 'SLB',\n",
       " 'STX',\n",
       " 'SRE',\n",
       " 'NOW',\n",
       " 'SHW',\n",
       " 'SPG',\n",
       " 'SWKS',\n",
       " 'SJM',\n",
       " 'SW',\n",
       " 'SNA',\n",
       " 'SOLV',\n",
       " 'SO',\n",
       " 'LUV',\n",
       " 'SWK',\n",
       " 'SBUX',\n",
       " 'STT',\n",
       " 'STLD',\n",
       " 'STE',\n",
       " 'SYK',\n",
       " 'SMCI',\n",
       " 'SYF',\n",
       " 'SNPS',\n",
       " 'SYY',\n",
       " 'TMUS',\n",
       " 'TROW',\n",
       " 'TTWO',\n",
       " 'TPR',\n",
       " 'TRGP',\n",
       " 'TGT',\n",
       " 'TEL',\n",
       " 'TDY',\n",
       " 'TFX',\n",
       " 'TER',\n",
       " 'TSLA',\n",
       " 'TXN',\n",
       " 'TXT',\n",
       " 'TMO',\n",
       " 'TJX',\n",
       " 'TSCO',\n",
       " 'TT',\n",
       " 'TDG',\n",
       " 'TRV',\n",
       " 'TRMB',\n",
       " 'TFC',\n",
       " 'TYL',\n",
       " 'TSN',\n",
       " 'USB',\n",
       " 'UBER',\n",
       " 'UDR',\n",
       " 'ULTA',\n",
       " 'UNP',\n",
       " 'UAL',\n",
       " 'UPS',\n",
       " 'URI',\n",
       " 'UNH',\n",
       " 'UHS',\n",
       " 'VLO',\n",
       " 'VTR',\n",
       " 'VLTO',\n",
       " 'VRSN',\n",
       " 'VRSK',\n",
       " 'VZ',\n",
       " 'VRTX',\n",
       " 'VTRS',\n",
       " 'VICI',\n",
       " 'V',\n",
       " 'VST',\n",
       " 'VMC',\n",
       " 'WRB',\n",
       " 'GWW',\n",
       " 'WAB',\n",
       " 'WBA',\n",
       " 'WMT',\n",
       " 'DIS',\n",
       " 'WBD',\n",
       " 'WM',\n",
       " 'WAT',\n",
       " 'WEC',\n",
       " 'WFC',\n",
       " 'WELL',\n",
       " 'WST',\n",
       " 'WDC',\n",
       " 'WY',\n",
       " 'WMB',\n",
       " 'WTW',\n",
       " 'WYNN',\n",
       " 'XEL',\n",
       " 'XYL',\n",
       " 'YUM',\n",
       " 'ZBRA',\n",
       " 'ZBH',\n",
       " 'ZTS']"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Essa célula será usada para se obter os tickets das companhias que fazem parte do S&P 500, com base em dados da wikipedia.\n",
    "'''\n",
    "\n",
    "# Salva em uma variável a url que contém a tabela com os tickets das companhias.\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "\n",
    "# Lê todas as tabelas presentes na url acima.\n",
    "sp500_table = pd.read_html(url)\n",
    "\n",
    "# Salva a coluna \"Symbol\" da primeira tabela em uma variável (tal coluna contém todos os tickets das companhias que fazem parte do S&P 500).\n",
    "sp500_symbols= sp500_table[0]['Symbol']\n",
    "\n",
    "# Transforma os tickets obtidos em uma lista.\n",
    "sp500_symbols = sp500_symbols.tolist()\n",
    "\n",
    "# Exibe a lista de tickets criada acima.\n",
    "sp500_symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Definindo alguns parâmetros que serão importantes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Essa célula será usada para criar um dicionário chamado setup, que contém os parâmetros principais que este código necessita. \n",
    "'''\n",
    "\n",
    "# Cria um dicionário para guardar alguns parâmetros importantes.\n",
    "setup = {\n",
    "    #\n",
    "    \"symbols\": sp500_symbols,\n",
    "    # Define a data inicial cujos dados serão coletados (Primeiro dia de negociações do S&P500 em 2019).\n",
    "    \"data_extraction_initial_date\": datetime(2019,1,2).date(), # Deve obrigatoriamente ser um dia de negociação.\n",
    "    # Define a data final cujos dados serão coletados (Último dia de negociações do S&P500 em 2023).\n",
    "    \"data_extraction_final_date\": datetime(2023,12,30).date(), # Deve obrigatoriamente ser um dia de negociação e deve também obrigatoriamente\n",
    "                                                               # suceder um dia de negociação.\n",
    "    \"features_time_period\": {\n",
    "        #\n",
    "        \"returns_time_period\": 1,\n",
    "        #\n",
    "        \"exponential_moving_average_time_period\": 14,\n",
    "        #\n",
    "        \"relative_strength_index_time_period\": 14,\n",
    "        #\n",
    "        \"average_true_range_time_period\": 14,\n",
    "        #\n",
    "        \"momemtum_time_period\": 14\n",
    "    },\n",
    "    \"lstm_sequences_length\": 14\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Criando a rede neural**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Este código define, constrói e compila um modelo LSTM (Long Short-Term Memory) para previsões de séries temporais.\n",
    "\n",
    "    Parâmetros dos métodos utilizados:\n",
    "    1. `LSTM`:\n",
    "        - `units`: Número de neurônios na camada LSTM.\n",
    "        - `return_sequences`: Se `True`, retorna a sequência completa de saídas para cada unidade LSTM; se `False`, retorna apenas \n",
    "           a saída final.\n",
    "        - `input_shape`: Tupla que define a forma da entrada (tamanho da sequência de tempo, número de features).\n",
    "\n",
    "    2. `Dropout`:\n",
    "        - `rate`: Fração de neurônios a serem descartados durante o treinamento para evitar overfitting.\n",
    "\n",
    "    3. `Dense`:\n",
    "        - `units`: Número de neurônios na camada densa (totalmente conectada). No contexto de regressão, geralmente é 1.\n",
    "\n",
    "    4. `compile`:\n",
    "        - `optimizer`: Algoritmo de otimização utilizado para ajustar os pesos do modelo. 'adam' é uma escolha comum para LSTM.\n",
    "        - `loss`: Função de perda que o modelo tentará minimizar durante o treinamento. Neste caso, 'mean_squared_error' (erro quadrático médio) é usado para problemas de regressão.\n",
    "\"\"\"\n",
    "\n",
    "def create_LSTM_model(features_number: int, lstm_sequence_length: int):\n",
    "    '''\n",
    "        Description:\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Return:\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Definindo o modelo LSTM\n",
    "    # Utilizamos o modelo 'Sequential', que permite empilhar camadas de forma linear. Esse tipo de modelo é adequado para a maioria das \n",
    "    # arquiteturas de rede neural onde as camadas são adicionadas uma após a outra.\n",
    "    model = Sequential()\n",
    "\n",
    "    # Adiciona a camada de entrada explicitamente\n",
    "    model.add(Input(shape=(lstm_sequence_length, features_number)))\n",
    "\n",
    "    # Adiciona a primeira camada LSTM com 64 unidades (neurônios).\n",
    "    model.add(LSTM(units=64, return_sequences=True))\n",
    "\n",
    "    # Adiciona uma camada de Dropout. Tal camada é usada para evitar overfitting durante o treinamento do modelo. Ao definir `rate=0.2`, \n",
    "    # estamos especificando que 20% dos neurônios da camada anterior serão desligados aleatoriamente em cada atualização do ciclo de treinamento.\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Adiciona uma segunda LSTM. Ao definirmos`return_sequences=False` indicamos que esta é a última camada LSTM na rede, e \n",
    "    # ela só retorna a última saída em vez de toda a sequência.\n",
    "    model.add(LSTM(units=128, return_sequences=False))\n",
    "\n",
    "    # Adiciona uma segunda camada de Dropout. Assim como antes, 20% dos neurônios serão desativados em cada iteração de treinamento.\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Adiciona a camada de saída. Tal camada é uma camada densa totalmente conectada com um único neurônio (units=1). Isso é adequado para \n",
    "    # problemas de regressão onde a previsão final é um único valor contínuo.\n",
    "    model.add(Dense(units=1))\n",
    "\n",
    "    # Compila o modelo criado. O modelo é compilado com o otimizador 'adam', que é eficiente para grandes volumes de dados e adequado para\n",
    "    # problemas de regressão. Além disso, setamos a função de perda como sendo a 'mean_squared_error' (MSE), que é uma escolha comum para medir \n",
    "    # o erro médio ao quadrado entre as previsões e os valores reais.\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # A variável 'model' agora contém o modelo LSTM compilado e pode ser usada para treinamento e previsões. Logo, retornamos ela\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_and_get_results(model: Sequential, X_train_scaled_sequences, X_test_scaled_sequences ,\n",
    "                                y_train_scaled_sequences, y_test_scaled_sequences) -> tuple[np.ndarray, float]:\n",
    "   '''\n",
    "      Description:\n",
    "      \n",
    "      Args:\n",
    "\n",
    "      Return:\n",
    "   '''\n",
    "      \n",
    "   \"\"\"\n",
    "      Este código treina o modelo LSTM usando o método `fit` do módulo Keras da biblioteca tensorflow.\n",
    "\n",
    "      Parâmetros do método `fit`:\n",
    "      1. `x`: Dados de entrada para treinamento. No contexto de séries temporais com LSTM, este é um array de sequências escaladas.\n",
    "      2. `y`: Dados de saída (alvo) para treinamento. Correspondem aos valores que o modelo deve prever com base nos dados de entrada.\n",
    "      3. `epochs`: Número de vezes que o modelo passará por todo o conjunto de dados de treinamento. Um número maior de épocas pode melhorar o \n",
    "         ajuste do modelo, mas também aumenta o risco de overfitting.\n",
    "      4. `batch_size`: Número de amostras que o modelo processa antes de atualizar os pesos. Tamanhos de batch menores podem resultar em um \n",
    "         treinamento mais ruidoso, mas permitem uma melhor generalização.\n",
    "      5. `validation_split`: Proporção dos dados de treinamento que será usada para validação. Ajuda a monitorar a performance do modelo em \n",
    "         dados que ele não viu durante o treinamento.\n",
    "      6. `verbose`: Nível de verbosidade do processo de treinamento. `verbose=1` exibe uma barra de progresso detalhada durante o treinamento.\n",
    "   \"\"\"\n",
    "\n",
    "   # Treina o modelo\n",
    "   # O método `fit` treina o modelo LSTM usando os dados de entrada (`X_train_scaled_sequence`) e as saídas correspondentes \n",
    "   # (`y_train_scaled_sequence`).\n",
    "   model.fit(\n",
    "      X_train_scaled_sequences,  # Dados de entrada de treino (sequências temporais)\n",
    "      y_train_scaled_sequences,  # Dados de saída de treino (valores de previsão para cada sequência)\n",
    "      epochs=50,  # Número de épocas: o modelo passará 50 vezes por todo o conjunto de dados de treinamento\n",
    "      batch_size=32,  # Tamanho do batch: o modelo ajusta os pesos após processar cada lote de 32 amostras\n",
    "      validation_split=0.2,  # 20% dos dados de treinamento serão usados para validação.\n",
    "      verbose=1  # Nível de verbosidade: 1 mostra uma barra de progresso e resultados após cada época\n",
    "   )\n",
    "   \n",
    "   \"\"\"\n",
    "         Este bloco de código faz previsões sobre um conjunto de dados de teste usando o modelo LSTM treinado acima, e, em seguida,\n",
    "         avalia a precisão dessas previsões usando a métrica de Root Mean Squared Error (RMSE).\n",
    "   \"\"\"\n",
    "\n",
    "   \n",
    "   # Realiza a previsão de valores para dados não vistos até então.\n",
    "   predicted = model.predict(X_test_scaled_sequences)\n",
    "\n",
    "   # Avalia, utilizando a métrica RMSE, o resultado das previsões feitas acima.\n",
    "   RMSE = np.sqrt(mean_squared_error(y_test_scaled_sequences,predicted))\n",
    "\n",
    "   return predicted, RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Testes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "ticker = Ticker('MMM', setup['data_extraction_initial_date'], setup['data_extraction_final_date'], setup['features_time_period'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-02</th>\n",
       "      <td>157.040131</td>\n",
       "      <td>159.690628</td>\n",
       "      <td>156.103683</td>\n",
       "      <td>159.657196</td>\n",
       "      <td>126.860451</td>\n",
       "      <td>2960339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03</th>\n",
       "      <td>157.424744</td>\n",
       "      <td>157.424744</td>\n",
       "      <td>152.918060</td>\n",
       "      <td>153.645493</td>\n",
       "      <td>122.083618</td>\n",
       "      <td>4016407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04</th>\n",
       "      <td>156.145493</td>\n",
       "      <td>160.518402</td>\n",
       "      <td>155.543472</td>\n",
       "      <td>159.966553</td>\n",
       "      <td>127.106232</td>\n",
       "      <td>3582140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-07</th>\n",
       "      <td>160.000000</td>\n",
       "      <td>160.785950</td>\n",
       "      <td>157.742477</td>\n",
       "      <td>159.598663</td>\n",
       "      <td>126.813919</td>\n",
       "      <td>2585991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-08</th>\n",
       "      <td>161.371231</td>\n",
       "      <td>162.299332</td>\n",
       "      <td>158.511703</td>\n",
       "      <td>160.267563</td>\n",
       "      <td>127.345436</td>\n",
       "      <td>2965841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-22</th>\n",
       "      <td>88.528427</td>\n",
       "      <td>89.807693</td>\n",
       "      <td>88.419731</td>\n",
       "      <td>88.904678</td>\n",
       "      <td>86.383255</td>\n",
       "      <td>2728913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-26</th>\n",
       "      <td>88.879601</td>\n",
       "      <td>90.794312</td>\n",
       "      <td>88.854515</td>\n",
       "      <td>90.392975</td>\n",
       "      <td>87.829346</td>\n",
       "      <td>3332176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27</th>\n",
       "      <td>90.301003</td>\n",
       "      <td>91.220734</td>\n",
       "      <td>90.033447</td>\n",
       "      <td>90.919731</td>\n",
       "      <td>88.341164</td>\n",
       "      <td>2922785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28</th>\n",
       "      <td>90.852844</td>\n",
       "      <td>92.123749</td>\n",
       "      <td>90.844482</td>\n",
       "      <td>91.714050</td>\n",
       "      <td>89.112961</td>\n",
       "      <td>3360282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29</th>\n",
       "      <td>91.555183</td>\n",
       "      <td>91.939796</td>\n",
       "      <td>90.928093</td>\n",
       "      <td>91.404678</td>\n",
       "      <td>88.812355</td>\n",
       "      <td>2887622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1258 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2019-01-02  157.040131  159.690628  156.103683  159.657196  126.860451   \n",
       "2019-01-03  157.424744  157.424744  152.918060  153.645493  122.083618   \n",
       "2019-01-04  156.145493  160.518402  155.543472  159.966553  127.106232   \n",
       "2019-01-07  160.000000  160.785950  157.742477  159.598663  126.813919   \n",
       "2019-01-08  161.371231  162.299332  158.511703  160.267563  127.345436   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2023-12-22   88.528427   89.807693   88.419731   88.904678   86.383255   \n",
       "2023-12-26   88.879601   90.794312   88.854515   90.392975   87.829346   \n",
       "2023-12-27   90.301003   91.220734   90.033447   90.919731   88.341164   \n",
       "2023-12-28   90.852844   92.123749   90.844482   91.714050   89.112961   \n",
       "2023-12-29   91.555183   91.939796   90.928093   91.404678   88.812355   \n",
       "\n",
       "             Volume  \n",
       "Date                 \n",
       "2019-01-02  2960339  \n",
       "2019-01-03  4016407  \n",
       "2019-01-04  3582140  \n",
       "2019-01-07  2585991  \n",
       "2019-01-08  2965841  \n",
       "...             ...  \n",
       "2023-12-22  2728913  \n",
       "2023-12-26  3332176  \n",
       "2023-12-27  2922785  \n",
       "2023-12-28  3360282  \n",
       "2023-12-29  2887622  \n",
       "\n",
       "[1258 rows x 6 columns]"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exibe os dados do ticker de teste antes deles serem \"ajustados\".\n",
    "ticker.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza o \"ajuste\" dos dados para o ticker em questão.\n",
    "ticker.adjust_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Log returns</th>\n",
       "      <th>B. upper bands</th>\n",
       "      <th>EMA</th>\n",
       "      <th>B. lower bands</th>\n",
       "      <th>RSI</th>\n",
       "      <th>ATR</th>\n",
       "      <th>MOM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-23</th>\n",
       "      <td>127.750694</td>\n",
       "      <td>1976868</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>130.629937</td>\n",
       "      <td>127.136236</td>\n",
       "      <td>123.642535</td>\n",
       "      <td>52.022916</td>\n",
       "      <td>3.724319</td>\n",
       "      <td>0.890244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-24</th>\n",
       "      <td>127.903442</td>\n",
       "      <td>1893029</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>129.357918</td>\n",
       "      <td>127.238530</td>\n",
       "      <td>125.119142</td>\n",
       "      <td>52.378923</td>\n",
       "      <td>3.557437</td>\n",
       "      <td>5.819824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-25</th>\n",
       "      <td>130.148987</td>\n",
       "      <td>2774840</td>\n",
       "      <td>0.017404</td>\n",
       "      <td>130.121977</td>\n",
       "      <td>127.626591</td>\n",
       "      <td>125.131205</td>\n",
       "      <td>57.385210</td>\n",
       "      <td>3.580450</td>\n",
       "      <td>3.042755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-28</th>\n",
       "      <td>128.355225</td>\n",
       "      <td>3775294</td>\n",
       "      <td>-0.013878</td>\n",
       "      <td>130.182002</td>\n",
       "      <td>127.723742</td>\n",
       "      <td>125.265482</td>\n",
       "      <td>52.625900</td>\n",
       "      <td>3.613165</td>\n",
       "      <td>1.541306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-29</th>\n",
       "      <td>130.846603</td>\n",
       "      <td>5156076</td>\n",
       "      <td>0.019224</td>\n",
       "      <td>131.019168</td>\n",
       "      <td>128.140124</td>\n",
       "      <td>125.261080</td>\n",
       "      <td>57.854172</td>\n",
       "      <td>3.754628</td>\n",
       "      <td>3.501167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-02</th>\n",
       "      <td>124.670410</td>\n",
       "      <td>3401902</td>\n",
       "      <td>0.001830</td>\n",
       "      <td>132.829676</td>\n",
       "      <td>124.215668</td>\n",
       "      <td>115.601661</td>\n",
       "      <td>52.884711</td>\n",
       "      <td>3.415187</td>\n",
       "      <td>6.061829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-03</th>\n",
       "      <td>124.998085</td>\n",
       "      <td>3437543</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>132.579895</td>\n",
       "      <td>124.319991</td>\n",
       "      <td>116.060087</td>\n",
       "      <td>53.542601</td>\n",
       "      <td>3.403566</td>\n",
       "      <td>6.553329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-04</th>\n",
       "      <td>126.152054</td>\n",
       "      <td>2192268</td>\n",
       "      <td>0.009190</td>\n",
       "      <td>132.425150</td>\n",
       "      <td>124.564266</td>\n",
       "      <td>116.703382</td>\n",
       "      <td>55.879131</td>\n",
       "      <td>3.268552</td>\n",
       "      <td>7.614700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-05</th>\n",
       "      <td>127.512596</td>\n",
       "      <td>2179590</td>\n",
       "      <td>0.010727</td>\n",
       "      <td>132.194577</td>\n",
       "      <td>124.957376</td>\n",
       "      <td>117.720176</td>\n",
       "      <td>58.527505</td>\n",
       "      <td>3.186183</td>\n",
       "      <td>9.587837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-08</th>\n",
       "      <td>128.759140</td>\n",
       "      <td>2816700</td>\n",
       "      <td>0.009728</td>\n",
       "      <td>132.548466</td>\n",
       "      <td>125.464278</td>\n",
       "      <td>118.380090</td>\n",
       "      <td>60.846430</td>\n",
       "      <td>3.069683</td>\n",
       "      <td>8.291428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>516 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Adj Close   Volume  Log returns  B. upper bands         EMA  \\\n",
       "Date                                                                       \n",
       "2019-01-23  127.750694  1976868     0.000156      130.629937  127.136236   \n",
       "2019-01-24  127.903442  1893029     0.001195      129.357918  127.238530   \n",
       "2019-01-25  130.148987  2774840     0.017404      130.121977  127.626591   \n",
       "2019-01-28  128.355225  3775294    -0.013878      130.182002  127.723742   \n",
       "2019-01-29  130.846603  5156076     0.019224      131.019168  128.140124   \n",
       "...                ...      ...          ...             ...         ...   \n",
       "2021-02-02  124.670410  3401902     0.001830      132.829676  124.215668   \n",
       "2021-02-03  124.998085  3437543     0.002625      132.579895  124.319991   \n",
       "2021-02-04  126.152054  2192268     0.009190      132.425150  124.564266   \n",
       "2021-02-05  127.512596  2179590     0.010727      132.194577  124.957376   \n",
       "2021-02-08  128.759140  2816700     0.009728      132.548466  125.464278   \n",
       "\n",
       "            B. lower bands        RSI       ATR       MOM  \n",
       "Date                                                       \n",
       "2019-01-23      123.642535  52.022916  3.724319  0.890244  \n",
       "2019-01-24      125.119142  52.378923  3.557437  5.819824  \n",
       "2019-01-25      125.131205  57.385210  3.580450  3.042755  \n",
       "2019-01-28      125.265482  52.625900  3.613165  1.541306  \n",
       "2019-01-29      125.261080  57.854172  3.754628  3.501167  \n",
       "...                    ...        ...       ...       ...  \n",
       "2021-02-02      115.601661  52.884711  3.415187  6.061829  \n",
       "2021-02-03      116.060087  53.542601  3.403566  6.553329  \n",
       "2021-02-04      116.703382  55.879131  3.268552  7.614700  \n",
       "2021-02-05      117.720176  58.527505  3.186183  9.587837  \n",
       "2021-02-08      118.380090  60.846430  3.069683  8.291428  \n",
       "\n",
       "[516 rows x 9 columns]"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exibe os dados do ticker em questão após os mesmos terem sido \"ajustados\".\n",
    "ticker.data.head(516)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_initial_day = pd.to_datetime(datetime(2021,1,19))\n",
    "test_final_day = pd.to_datetime(datetime(2021,2,8))\n",
    "\n",
    "X_train_scaled_sequences, X_test_scaled_sequences, y_train_scaled_sequences, y_test_scaled_sequences = ticker.prepare_data_for_lstm(test_initial_day, test_final_day, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_number = len(X_train_scaled_sequences[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_LSTM_model(features_number, setup['lstm_sequences_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 94ms/step - loss: 0.0644 - val_loss: 0.0043\n",
      "Epoch 2/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.0111 - val_loss: 0.0056\n",
      "Epoch 3/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.0089 - val_loss: 0.0024\n",
      "Epoch 4/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - loss: 0.0067 - val_loss: 0.0022\n",
      "Epoch 5/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.0066 - val_loss: 0.0028\n",
      "Epoch 6/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0069 - val_loss: 0.0021\n",
      "Epoch 7/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0062 - val_loss: 0.0022\n",
      "Epoch 8/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0049 - val_loss: 0.0021\n",
      "Epoch 9/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0067 - val_loss: 0.0032\n",
      "Epoch 10/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0058 - val_loss: 0.0023\n",
      "Epoch 11/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0042 - val_loss: 0.0015\n",
      "Epoch 12/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 13/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0044 - val_loss: 0.0021\n",
      "Epoch 14/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0043 - val_loss: 0.0013\n",
      "Epoch 15/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0040 - val_loss: 0.0013\n",
      "Epoch 16/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0038 - val_loss: 0.0018\n",
      "Epoch 17/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 18/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0043 - val_loss: 0.0013\n",
      "Epoch 19/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 20/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 21/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0043 - val_loss: 0.0015\n",
      "Epoch 22/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0044 - val_loss: 0.0011\n",
      "Epoch 23/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.0035 - val_loss: 0.0014\n",
      "Epoch 24/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 25/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 26/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0040 - val_loss: 0.0014\n",
      "Epoch 27/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0049 - val_loss: 0.0012\n",
      "Epoch 28/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.0037 - val_loss: 0.0011\n",
      "Epoch 30/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0037 - val_loss: 0.0011\n",
      "Epoch 31/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 32/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.0039 - val_loss: 0.0017\n",
      "Epoch 33/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0044 - val_loss: 0.0015\n",
      "Epoch 34/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 35/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 36/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0037 - val_loss: 0.0011\n",
      "Epoch 37/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 38/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0031 - val_loss: 9.7107e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 40/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 41/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - loss: 0.0039 - val_loss: 0.0011\n",
      "Epoch 42/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 43/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.0029 - val_loss: 9.9340e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 45/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.0033 - val_loss: 0.0010\n",
      "Epoch 46/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0033 - val_loss: 9.5524e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0029 - val_loss: 0.0010\n",
      "Epoch 48/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 49/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 50/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.0034 - val_loss: 0.0010\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471ms/step\n"
     ]
    }
   ],
   "source": [
    "predicted, RMSE = train_model_and_get_results(model, X_train_scaled_sequences, X_test_scaled_sequences, y_train_scaled_sequences, y_test_scaled_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04736078249112663"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
